{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "409d5a27-a7ba-4ee3-becd-e780228708fa",
   "metadata": {},
   "source": [
    "# Generating mocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff258ca5-1f31-4c63-972f-6cf7ee59de45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Generates mock datasets in Parquet format for testing the CRC pipeline.\n",
    "\n",
    "Generated files:\n",
    "1) test_survey_not_supported.parquet\n",
    "2) test_homogenized_columns_out_of_range.parquet\n",
    "3) test_survey_col_missing.parquet\n",
    "4) test_survey_supported_but_wrong_flags.parquet\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Number of rows in each dataset\n",
    "N_ROWS = 100\n",
    "\n",
    "# Seed for reproduction (adjust or remove if you want it completely random)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "def random_sky_coordinates(n: int):\n",
    "    \"\"\"Generate random RA/DEC on the sky (simple uniform in RA and DEC).\"\"\"\n",
    "    ra = np.random.uniform(0.0, 360.0, n)    # RA em graus [0, 360)\n",
    "    dec = np.random.uniform(-90.0, 90.0, n)  # DEC em graus [-90, 90]\n",
    "    return ra, dec\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1) test_survey_not_supported.parquet\n",
    "# ------------------------------------------------------------\n",
    "# colunas: id, ra, dec, z, z_flag, survey\n",
    "# - survey: \"not_supported\"\n",
    "# - z_flag: [1, 10]\n",
    "# - id: \"1_001\", \"1_002\", ...\n",
    "# - z: float em [0, 1]\n",
    "# ============================================================\n",
    "\n",
    "ra1, dec1 = random_sky_coordinates(N_ROWS)\n",
    "\n",
    "df1 = pd.DataFrame({\n",
    "    \"id\": [f\"1_{i:03d}\" for i in range(1, N_ROWS + 1)],\n",
    "    \"ra\": ra1,\n",
    "    \"dec\": dec1,\n",
    "    \"z\": np.random.uniform(0.0, 1.0, N_ROWS),\n",
    "    \"z_flag\": np.random.randint(1, 11, N_ROWS),  # 1 a 10 (high Ã© exclusivo)\n",
    "    \"survey\": [\"not_supported\"] * N_ROWS,\n",
    "})\n",
    "\n",
    "df1.to_parquet(\"test_survey_not_supported.parquet\", index=False)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) test_homogenized_columns_out_of_range.parquet\n",
    "# ------------------------------------------------------------\n",
    "# colunas: id, ra, dec, z, z_flag_homogenized,\n",
    "#          instrument_type_homogenized, survey\n",
    "# - survey: \"wrong_homogenized\"\n",
    "# - z_flag_homogenized: [1, 10]\n",
    "# - id: \"2_001\", \"2_002\", ...\n",
    "# - z: float em [0, 1]\n",
    "# ============================================================\n",
    "\n",
    "ra2, dec2 = random_sky_coordinates(N_ROWS)\n",
    "\n",
    "instrument_types = [\"galaxy\", \"qso\", \"star\"]\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    \"id\": [f\"2_{i:03d}\" for i in range(1, N_ROWS + 1)],\n",
    "    \"ra\": ra2,\n",
    "    \"dec\": dec2,\n",
    "    \"z\": np.random.uniform(0.0, 1.0, N_ROWS),\n",
    "    \"z_flag_homogenized\": np.random.randint(1, 11, N_ROWS),  # 1 a 10\n",
    "    \"instrument_type_homogenized\": np.random.choice(instrument_types, N_ROWS),\n",
    "    \"survey\": [\"wrong_homogenized\"] * N_ROWS,\n",
    "})\n",
    "\n",
    "df2.to_parquet(\"test_homogenized_columns_out_of_range.parquet\", index=False)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3) test_survey_col_missing.parquet\n",
    "# ------------------------------------------------------------\n",
    "# colunas: id, ra, dec, z, z_flag   (SEM survey)\n",
    "# - z_flag: [1, 10]\n",
    "# - id: \"3_001\", \"3_002\", ...\n",
    "# - z: float em [0, 1]\n",
    "# ============================================================\n",
    "\n",
    "ra3, dec3 = random_sky_coordinates(N_ROWS)\n",
    "\n",
    "df3 = pd.DataFrame({\n",
    "    \"id\": [f\"3_{i:03d}\" for i in range(1, N_ROWS + 1)],\n",
    "    \"ra\": ra3,\n",
    "    \"dec\": dec3,\n",
    "    \"z\": np.random.uniform(0.0, 1.0, N_ROWS),\n",
    "    \"z_flag\": np.random.randint(1, 11, N_ROWS),  # 1 a 10\n",
    "    # intencionalmente sem coluna \"survey\"\n",
    "})\n",
    "\n",
    "df3.to_parquet(\"test_survey_col_missing.parquet\", index=False)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4) test_survey_supported_but_wrong_flags.parquet\n",
    "# ------------------------------------------------------------\n",
    "# colunas: id, ra, dec, z, z_flag, survey\n",
    "# - survey: \"2DFGRS\"\n",
    "# - z_flag: [10, 20]\n",
    "# - id: \"4_001\", \"4_002\", ...\n",
    "# - z: float em [0, 1]\n",
    "# ============================================================\n",
    "\n",
    "ra4, dec4 = random_sky_coordinates(N_ROWS)\n",
    "\n",
    "df4 = pd.DataFrame({\n",
    "    \"id\": [f\"4_{i:03d}\" for i in range(1, N_ROWS + 1)],\n",
    "    \"ra\": ra4,\n",
    "    \"dec\": dec4,\n",
    "    \"z\": np.random.uniform(0.0, 1.0, N_ROWS),\n",
    "    \"z_flag\": np.random.randint(10, 21, N_ROWS),  # 10 a 20\n",
    "    \"survey\": [\"2DFGRS\"] * N_ROWS,\n",
    "})\n",
    "\n",
    "df4.to_parquet(\"test_survey_supported_but_wrong_flags.parquet\", index=False)\n",
    "\n",
    "\n",
    "print(\"Arquivos Parquet gerados com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f9ad98-c710-45a8-b72d-73d283c98969",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121a0373-ea5a-49b0-93e3-6327b5e3f26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e26a14-062e-4ca7-a288-df4f2b880651",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_parquet(\"test_survey_not_supported.parquet\")\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8516b4d3-7498-4b2a-8f96-c637cfce3941",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_parquet(\"test_homogenized_columns_out_of_range.parquet\")\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daed2bbb-4822-419c-ba16-9b9440994181",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = pd.read_parquet(\"test_survey_col_missing.parquet\")\n",
    "df_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b000317-94a3-485a-ba56-d1d2612f61b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = pd.read_parquet(\"test_survey_supported_but_wrong_flags.parquet\")\n",
    "df_4.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CONDA_ENV_data_preparation",
   "language": "python",
   "name": "conda_env_data_preparation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
