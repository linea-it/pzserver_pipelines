{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06d2c6aa-e836-4c37-b67f-b8a828c80590",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351b9448-1cdf-46a1-b07c-b031c3c5f12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "user = getpass.getuser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921fa07e-c9e5-4ff5-bfa9-ff27115717d6",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c66b946-64d0-4182-aca2-1268f6b3a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# CONFIGURATION SECTION\n",
    "# =========================================================\n",
    "#input_paths = [\n",
    "#    f\"/scratch/users/{user}/speczs-catalogs/processed/2dfgrs_final_release.parquet\",\n",
    "#    f\"/scratch/users/{user}/speczs-catalogs/processed/2dflens_final_release.parquet\",\n",
    "#    f\"/scratch/users/{user}/speczs-catalogs/processed/2mrs_v240.parquet\",\n",
    "#    f\"/scratch/users/{user}/speczs-catalogs/processed/3dhst_v4.1.5.parquet\",\n",
    "#    f\"/scratch/users/{user}/speczs-catalogs/processed/6dfgs_dr3.parquet\",\n",
    "#    f\"/scratch/users/{user}/speczs-catalogs/processed/astrodeep_jwst.parquet\",\n",
    "#    f\"/scratch/users/luigi.silva/speczs-catalogs/processed/astrodeep-gs43.parquet\",\n",
    "#    f\"/scratch/users/{user}/speczs-catalogs/processed/desi_dr1_in_lsst_dp1_fields.parquet\",\n",
    "#    f\"/scratch/users/{user}/speczs-catalogs/processed/jades_dr3.parquet\",\n",
    "#    f\"/scratch/users/{user}/speczs-catalogs/processed/mosdef_final_release.parquet\",\n",
    "#    f\"/scratch/users/{user}/speczs-catalogs/processed/ozdes_dr2.parquet\",\n",
    "#    f\"/scratch/users/{user}/speczs-catalogs/processed/primus_dr1.parquet\",\n",
    "#    f\"/scratch/users/{user}/speczs-catalogs/processed/vandels_dr4.parquet\",\n",
    "#    f\"/scratch/users/{user}/speczs-catalogs/processed/vlt_vimos_v2.0.1.parquet\",\n",
    "#    f\"/scratch/users/{user}/speczs-catalogs/processed/vuds_dr1.parquet\",\n",
    "#    f\"/scratch/users/{user}/speczs-catalogs/processed/vvds_final_release.parquet\",\n",
    "#    f\"/scratch/users/{user}/speczs-catalogs/johns-catalogs/z_cat_CANDELS_clean_sitcomtn-154.parquet\",\n",
    "#    f\"/scratch/users/{user}/speczs-catalogs/johns-catalogs/z_cat_NED_clean_sitcomtn-154.parquet\",\n",
    "#    f\"/scratch/users/{user}/pzserver_pipelines/combine_redshift_dedup/test_data/pipeline_generated_sample.parquet\"\n",
    "#]\n",
    "\n",
    "input_paths = glob.glob('test_data/*.parquet')\n",
    "\n",
    "final_catalog_path = f\"./process001/outputs/crd.parquet\"\n",
    "prepared_temp_dir = f\"./process001/temp/\"\n",
    "\n",
    "combine_mode = \"concatenate_and_mark_duplicates\" # Options: \"concatenate\", \"concatenate_and_mark_duplicates\", or \"concatenate_and_remove_duplicates\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b1390e-4d78-46dc-a879-93741200e42d",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9d742f-2815-4c78-b471-ed538be842b7",
   "metadata": {},
   "source": [
    "## Basic Info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db2c2af-86a5-4c2c-abfb-3f304ed3b90d",
   "metadata": {},
   "source": [
    "Counting input and output rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae0ff59-ef63-4ff9-886f-37606a01cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# COUNT INPUT ROWS\n",
    "# =========================================================\n",
    "total_input_rows = 0\n",
    "for path in input_paths:\n",
    "    if os.path.exists(path):\n",
    "        parquet_file = pq.ParquetFile(path)\n",
    "        n_rows = parquet_file.metadata.num_rows\n",
    "        print(f\"{path} -> {n_rows} rows\")\n",
    "        total_input_rows += n_rows\n",
    "    else:\n",
    "        warnings.warn(f\"⚠️ File not found: {path}\")\n",
    "\n",
    "print(f\"✅ Total number of input rows: {total_input_rows}\")\n",
    "\n",
    "# =========================================================\n",
    "# LOAD FINAL MERGED CATALOG\n",
    "# =========================================================\n",
    "if not os.path.exists(final_catalog_path):\n",
    "    raise FileNotFoundError(f\"❌ Final catalog not found: {final_catalog_path}\")\n",
    "\n",
    "df_final = pd.read_parquet(final_catalog_path)\n",
    "print(f\"✅ Total number of rows in final catalog: {len(df_final)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d55c9e8-c4e8-4c7b-a057-8f3fd80471c0",
   "metadata": {},
   "source": [
    "Printing the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46685e01-a0c4-4da7-b5cf-3e7a43794889",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed728553-feda-4264-aee8-482e202f6443",
   "metadata": {},
   "source": [
    "Dataframe columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6a85f2-2deb-419b-84f0-893ccbf4ce3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4c7fcd-64de-489a-8254-f83e08a2abbc",
   "metadata": {},
   "source": [
    "Dataframe columns types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba9d0d0-c23e-41d4-a01c-3e53161f01eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db02aa8-5dea-41c3-9807-a18308f4b93e",
   "metadata": {},
   "source": [
    "Basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfff02fa-50be-4d05-ae3b-d62ae76df68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if combine_mode != \"concatenate\":\n",
    "    display(df_final.drop(columns=[\"group_id\"]).describe())\n",
    "else:\n",
    "    display(df_final.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332f2bdc-55a9-463c-859b-9dbb1ecd1e57",
   "metadata": {},
   "source": [
    "Counting tie_result values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf326961-1cf0-4587-a47c-bbec4a99dc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "if combine_mode != \"concatenate\":\n",
    "    print(df_final[\"tie_result\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cd6ce4-6d28-484f-bf65-68b44085a852",
   "metadata": {},
   "source": [
    "Counting source values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a2a90c-386c-4904-824a-547509576407",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[\"source\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99e8dd0-f6cc-4310-a896-fba216515967",
   "metadata": {},
   "source": [
    "Checking the percentage of unsolved objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818d2df1-3df5-45a3-a1bb-217a2925c591",
   "metadata": {},
   "outputs": [],
   "source": [
    "if combine_mode != \"concatenate\":\n",
    "    # Total number of objects\n",
    "    total_all = len(df_final)\n",
    "    \n",
    "    # Filter objects that were compared (compared_to is not null or empty)\n",
    "    if \"compared_to\" in df_final.columns.to_list():\n",
    "        mask_compared = df_final[\"compared_to\"].notna() & (df_final[\"compared_to\"] != \"\")\n",
    "        df_compared = df_final[mask_compared]\n",
    "        \n",
    "        # Count how many have tie_result == 2\n",
    "        count_tie2 = (df_final[\"tie_result\"] == 2).sum()\n",
    "        count_tie2_compared = (df_compared[\"tie_result\"] == 2).sum()\n",
    "        \n",
    "        # Percentages\n",
    "        percent_all = (count_tie2 / total_all) * 100 if total_all > 0 else 0\n",
    "        percent_compared = (count_tie2_compared / len(df_compared)) * 100 if len(df_compared) > 0 else 0\n",
    "        \n",
    "        # Formatted print\n",
    "        print(f\"📊 tie_result == 2 represents:\")\n",
    "        print(f\"  • {percent_all:.2f}% of the total ({count_tie2} out of {total_all})\")\n",
    "        print(f\"  • {percent_compared:.2f}% of the compared objects ({count_tie2_compared} out of {len(df_compared)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19122dc4-9a55-41ff-8c00-2ab72eda2b89",
   "metadata": {},
   "source": [
    "## Individual Catalogs Deduplication Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b87f693-072b-48ea-bf78-e7fad7f351c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if combine_mode != \"concatenate\":\n",
    "    if \"test_data/pipeline_generated_sample.parquet\" in input_paths:\n",
    "        df_final_val = df_final[df_final[\"source\"] != \"019_pipeline_sample\"]\n",
    "    else:\n",
    "        df_final_val = df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74320729-c712-4a7a-88ce-549891c2b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "if combine_mode != \"concatenate\":\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    \n",
    "    import validation_functions as vf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e7d96d-f5e5-4368-b9db-99e8fa689376",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if combine_mode != \"concatenate\":\n",
    "    if \"compared_to\" in df_final.columns.to_list():\n",
    "        res = vf.validate_intra_source_cells_fast(df_final_val, ndp=4, source_col=\"source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0d138e-ab3e-488d-ab95-a36a0ac1ae8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if combine_mode != \"concatenate\":\n",
    "    if \"compared_to\" in df_final.columns.to_list():\n",
    "        vf.explain_intra_source_validation_output(\n",
    "            res,\n",
    "            top_k=5,\n",
    "            df_original=df_final_val,   \n",
    "            ndp_used=4,\n",
    "            samples_per_source=2,   \n",
    "            max_sources=5,         \n",
    "            source_col=\"source\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220d3621-1cf4-4aa1-94f8-6a6f7dfb5985",
   "metadata": {},
   "source": [
    "## Cross Catalog Deduplication Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d2e1b6-0f02-4ff9-baab-a029cfce7315",
   "metadata": {},
   "outputs": [],
   "source": [
    "if combine_mode != \"concatenate\":\n",
    "    report = vf.validate_tie_results_fast(df_final_val, threshold=0.0005, max_groups=40000, include_rows=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246692ac-5c4a-465c-8802-2ab6831b6e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if combine_mode != \"concatenate\":\n",
    "    vf.explain_tie_validation_output(report, show_per_rule=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df7b3a3-d1f0-405e-b28a-b2c6b9a63e1d",
   "metadata": {},
   "source": [
    "## Non-compared Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df988e3a-dda3-43fb-931a-415420204d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "if combine_mode != \"concatenate\":\n",
    "    if \"compared_to\" in df_final.columns.to_list():\n",
    "        result = vf.render_na_compared_to_validation(df_final_val, show_max=10, assert_if_invalid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1754379f-3e1b-417c-bf27-8a36ce31ed26",
   "metadata": {},
   "source": [
    "## Own Pipeline Product Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9c3797-ca65-474e-9852-ec3ab2f7ecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if combine_mode != \"concatenate\":\n",
    "    if \"compared_to\" in df_final.columns.to_list():\n",
    "        df_original = pd.read_parquet(\"test_data/pipeline_generated_sample.parquet\")\n",
    "        df_processed = df_final[df_final[\"source\"] == \"019_pipeline_sample\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a98c9d-412d-44f8-bb1e-f720e3ab9146",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if combine_mode != \"concatenate\":\n",
    "    if \"compared_to\" in df_final.columns.to_list():\n",
    "        res = vf.validate_tie_preservation(df_original, df_processed, key=\"CRD_ID\")\n",
    "        print(vf.explain_tie_preservation(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f35e40-d969-4e3c-b91c-31bd567318ce",
   "metadata": {},
   "source": [
    "## Manual Validation (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb72123e-ecb3-47b4-bac3-9e131207f02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if combine_mode != \"concatenate\":\n",
    "    if \"compared_to\" in df_final.columns.to_list():\n",
    "        df_for_manual = df_final[[\n",
    "            \"CRD_ID\",\"ra\",\"dec\",\"z\",\"survey\",\"source\",\n",
    "            \"tie_result\",\"compared_to\",\"z_flag_homogenized\",\n",
    "            \"instrument_type_homogenized\",\"group_id\"\n",
    "        ]]\n",
    "    else:\n",
    "        df_for_manual = df_final[[\n",
    "            \"CRD_ID\",\"ra\",\"dec\",\"z\",\"survey\",\"source\",\n",
    "            \"tie_result\",\"z_flag_homogenized\",\n",
    "            \"instrument_type_homogenized\",\"group_id\"\n",
    "        ]]    \n",
    "        \n",
    "    results = vf.analyze_groups_by_group_id_fast(\n",
    "        df_for_manual,\n",
    "        threshold=0.0005,\n",
    "        max_groups=10000,\n",
    "        max_examples_per_case=3,\n",
    "        render=True,\n",
    "        compute_same_source_pair=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ce0a4d-c7cd-4e8e-966b-ea27d80e0b8b",
   "metadata": {},
   "source": [
    "## Validation of groups with compared_to `<NA>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b19b3c9-515c-4001-ac0b-63e021586552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def check_group_id_integrity(\n",
    "    df: pd.DataFrame,\n",
    "    group_col: str = \"group_id\",\n",
    "    compared_col: str = \"compared_to\",\n",
    "    id_col: str = \"CRD_ID\",\n",
    "    zf_col: str = \"z_flag_homogenized\",\n",
    "    show_examples: int = 5,\n",
    "):\n",
    "    if group_col not in df.columns:\n",
    "        raise KeyError(f\"'{group_col}' não está no DataFrame.\")\n",
    "\n",
    "    # compared_to como string segura (ou vazio, se a coluna não existir)\n",
    "    if compared_col in df.columns:\n",
    "        cmp_str = df[compared_col].astype(\"string\").fillna(\"\").str.strip()\n",
    "    else:\n",
    "        cmp_str = pd.Series([\"\"] * len(df), index=df.index, dtype=\"string\")\n",
    "\n",
    "    # flags linha-a-linha\n",
    "    cmp_nonempty = cmp_str.ne(\"\")\n",
    "    is_star = pd.Series(False, index=df.index)\n",
    "    if zf_col in df.columns:\n",
    "        is_star = pd.to_numeric(df[zf_col], errors=\"coerce\").eq(6)\n",
    "\n",
    "    # agregações por group_id (inclui NaN se houver)\n",
    "    gkey = df[group_col]\n",
    "    size = gkey.groupby(gkey, dropna=False).size().rename(\"size\")\n",
    "    n_cmp_nonempty = cmp_nonempty.groupby(gkey, dropna=False).sum().rename(\"n_cmp_nonempty\")\n",
    "    n_star = is_star.groupby(gkey, dropna=False).sum().rename(\"n_star\")\n",
    "\n",
    "    stats = pd.concat([size, n_cmp_nonempty, n_star], axis=1).fillna(0)\n",
    "    stats[\"n_cmp_nonempty\"] = stats[\"n_cmp_nonempty\"].astype(int)\n",
    "    stats[\"n_star\"] = stats[\"n_star\"].astype(int)\n",
    "\n",
    "    # suspeitos = grupos com 2+ linhas e NENHUM compared_to preenchido\n",
    "    suspects = stats[(stats[\"size\"] >= 2) & (stats[\"n_cmp_nonempty\"] == 0)]\n",
    "\n",
    "    print(f\"Grupos suspeitos (size ≥ 2 e compared_to vazio para todos): {len(suspects)}\")\n",
    "    if len(suspects) > 0:\n",
    "        display(suspects.sort_values([\"size\"], ascending=False).head(10))\n",
    "        ex_gids = suspects.index[:show_examples]\n",
    "        cols = [c for c in [id_col, \"survey\", \"source\", \"z\", zf_col, compared_col, group_col] if c in df.columns]\n",
    "        sample = df[df[group_col].isin(ex_gids)].loc[:, cols].sort_values([group_col, id_col], na_position=\"last\")\n",
    "        display(sample)\n",
    "\n",
    "    # retorno útil para salvar/inspecionar depois\n",
    "    return {\"stats\": stats, \"suspects\": suspects}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f5890c-4b64-41e9-8a03-ffe9d3a8f369",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = check_group_id_integrity(df_final)\n",
    "assert len(out[\"suspects\"]) == 0, \"There is group_id with size>=2 and compared_to empty!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801271a1-eeb4-402d-a97c-46de5cb47376",
   "metadata": {},
   "source": [
    "## Validation - Prepared Catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c38638-040b-43cc-9c0b-fb22ba0e0dd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dicionário de regras equivalente ao YAML\n",
    "translation_rules = {\n",
    "    \"2DFGRS\": {\n",
    "        \"z_flag_translation\": {1: 0, 2: 1, 3: 3, 4: 4, 5: 4},\n",
    "        \"instrument_type_translation\": {\"default\": \"s\"},\n",
    "    },\n",
    "    \"2DFLENS\": {\n",
    "        \"z_flag_translation\": {1: 0, 2: 1, 3: 3, 4: 4, 6: 6},\n",
    "        \"instrument_type_translation\": {\"default\": \"s\"},\n",
    "    },\n",
    "    \"2MRS\": {\n",
    "        \"z_flag_translation\": {\n",
    "            \"conditions\": [\n",
    "                {\"expr\": \"z_err == 0\", \"value\": 3},\n",
    "                {\"expr\": \"0 < z_err < 0.0005\", \"value\": 4},\n",
    "                {\"expr\": \"z_err >= 0.0005\", \"value\": 3},\n",
    "            ],\n",
    "            \"default\": 0,\n",
    "        },\n",
    "        \"instrument_type_translation\": {\"default\": \"s\"},\n",
    "    },\n",
    "    \"3D-HST\": {\n",
    "        \"z_flag_translation\": {\n",
    "            \"conditions\": [\n",
    "                {\"expr\": \"z_best_s == 0\", \"value\": 6},\n",
    "                {\"expr\": \"z_best_s == 1 and z_spec != -1\", \"value\": 4},\n",
    "                {\"expr\": \"z_best_s == 2 and use_zgrism == 1 and flag1 == 0 and flag2 == 0\", \"value\": 3},\n",
    "                {\"expr\": \"z_best_s == 3 and use_phot == 1\", \"value\": 3},\n",
    "            ],\n",
    "            \"default\": 0,\n",
    "        },\n",
    "        \"instrument_type_translation\": {\n",
    "            \"conditions\": [\n",
    "                {\"expr\": \"z_best_s == 1\", \"value\": \"s\"},\n",
    "                {\"expr\": \"z_best_s == 2\", \"value\": \"g\"},\n",
    "                {\"expr\": \"z_best_s == 3\", \"value\": \"p\"},\n",
    "            ],\n",
    "            \"default\": \"g\",\n",
    "        },\n",
    "    },\n",
    "    \"6DFGS\": {\n",
    "        \"z_flag_translation\": {1: 0, 2: 1, 3: 3, 4: 4, 6: 6},\n",
    "        \"instrument_type_translation\": {\"default\": \"s\"},\n",
    "    },\n",
    "    \"ASTRODEEP\": {\n",
    "        \"z_flag_translation\": {\n",
    "            \"conditions\": [\n",
    "                {\"expr\": \"zspec_survey != '-'\", \"value\": 4},\n",
    "                {\"expr\": \"zspec_survey == '-'\", \"value\": 3},\n",
    "            ],\n",
    "            \"default\": 0,\n",
    "        },\n",
    "        \"instrument_type_translation\": {\n",
    "            \"conditions\": [\n",
    "                {\"expr\": \"zspec_survey != '-'\", \"value\": \"s\"},\n",
    "                {\"expr\": \"zspec_survey == '-'\", \"value\": \"p\"},\n",
    "            ],\n",
    "            \"default\": \"p\",\n",
    "        },\n",
    "    },\n",
    "    \"ASTRODEEP-JWST\": {\n",
    "        \"z_flag_translation\": {\n",
    "            \"conditions\": [\n",
    "                {\"expr\": \"zspec != -99 and z_flag < 400 and (len(str(int(z_flag))) <= 1 or int(str(int(z_flag))[-2]) <= 3)\", \"value\": 4},\n",
    "                {\"expr\": \"zspec == -99 and z_flag < 400 and (len(str(int(z_flag))) <= 1 or int(str(int(z_flag))[-2]) <= 3)\", \"value\": 3},\n",
    "            ],\n",
    "            \"default\": 0,\n",
    "        },\n",
    "        \"instrument_type_translation\": {\n",
    "            \"conditions\": [\n",
    "                {\"expr\": \"zspec != -99\", \"value\": \"s\"},\n",
    "                {\"expr\": \"zspec == -99\", \"value\": \"p\"},\n",
    "            ],\n",
    "            \"default\": \"p\",\n",
    "        },\n",
    "    },\n",
    "    \"DESI\": {\n",
    "        \"z_flag_translation\": {\n",
    "            \"conditions\": [\n",
    "                {\"expr\": \"ZCAT_PRIMARY != True\", \"value\": 0},\n",
    "                {\"expr\": \"z_flag != 0 and ZCAT_PRIMARY == True\", \"value\": 1},\n",
    "                {\"expr\": \"z_flag == 0 and ZCAT_PRIMARY == True and z_err < 0.0005\", \"value\": 4},\n",
    "                {\"expr\": \"z_flag == 0 and ZCAT_PRIMARY == True and z_err >= 0.0005\", \"value\": 3},\n",
    "            ],\n",
    "            \"default\": 0,\n",
    "        },\n",
    "        \"instrument_type_translation\": {\"default\": \"s\"},\n",
    "    },\n",
    "    \"JADES\": {\n",
    "        \"z_flag_translation\": {4: 4, 3: 3, 2: 2, 1: 1, 0: 0},\n",
    "        \"instrument_type_translation\": {\"default\": \"s\"},\n",
    "    },\n",
    "    \"MOSDEF\": {\n",
    "        \"z_flag_translation\": {7: 4, 6: 3, 5: 2, 4: 2, 3: 1, 2: 1, 1: 0, 0: 0},\n",
    "        \"instrument_type_translation\": {\"default\": \"s\"},\n",
    "    },\n",
    "    \"OZDES\": {\n",
    "        \"z_flag_translation\": {1: 0, 2: 1, 3: 3, 4: 4, 6: 6},\n",
    "        \"instrument_type_translation\": {\"default\": \"s\"},\n",
    "    },\n",
    "    \"PRIMUS\": {\n",
    "        \"z_flag_translation\": {-1: 0, 2: 1, 3: 2, 4: 3},\n",
    "        \"instrument_type_translation\": {\"default\": \"g\"},\n",
    "    },\n",
    "    \"VANDELS\": {\n",
    "        \"z_flag_translation\": {\n",
    "            0: 0, 1: 1, 2: 2, 3: 4, 4: 4, 9: 3,\n",
    "            10: 0, 11: 1, 12: 2, 13: 4, 14: 4, 19: 3,\n",
    "            20: 0, 21: 1, 22: 2, 23: 4, 24: 4, 29: 3,\n",
    "            210: 0, 211: 1, 212: 2, 213: 4, 214: 4, 219: 3,\n",
    "        },\n",
    "        \"instrument_type_translation\": {\"default\": \"s\"},\n",
    "    },\n",
    "    \"VIMOS\": {\n",
    "        \"z_flag_translation\": {4: 4, 3: 3, 2: 2, 1: 1, 0: 0},\n",
    "        \"instrument_type_translation\": {\"default\": \"s\"},\n",
    "    },\n",
    "    \"VUDS\": {\n",
    "        \"z_flag_translation\": {\n",
    "            1: 1, 11: 1, 21: 1, 31: 1, 41: 1,\n",
    "            2: 2, 12: 2, 22: 2, 32: 2, 42: 2, 9: 2, 19: 2, 29: 2, 39: 2, 49: 2,\n",
    "            3: 3, 13: 3, 23: 3, 33: 3, 43: 3,\n",
    "            4: 4, 14: 4, 24: 4, 34: 4, 44: 4,\n",
    "        },\n",
    "        \"instrument_type_translation\": {\"default\": \"s\"},\n",
    "    },\n",
    "    \"VVDS\": {\n",
    "        \"z_flag_translation\": {\n",
    "            0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 9: 2,\n",
    "            10: 0, 11: 1, 12: 2, 13: 3, 14: 4, 19: 2,\n",
    "            20: 0, 21: 1, 22: 2, 23: 3, 24: 4, 29: 2,\n",
    "            210: 0, 211: 1, 212: 2, 213: 3, 214: 4, 219: 2,\n",
    "        },\n",
    "        \"instrument_type_translation\": {\"default\": \"s\"},\n",
    "    },\n",
    "\n",
    "    # Special cases using continuous rule and inherited type\n",
    "    \"CANDELS\": {\"_special\": \"CANDELS_NED\"},\n",
    "    \"NED\": {\"_special\": \"CANDELS_NED\"},\n",
    "}\n",
    "\n",
    "def _safe_eval_expr(expr: str, ctx: dict) -> bool:\n",
    "    \"\"\"\n",
    "    Avalia 'expr' usando apenas variáveis do ctx e funções básicas.\n",
    "    Retorna True/False; se der erro, retorna False.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Permitir apenas funções básicas e numpy\n",
    "        allowed_globals = {\n",
    "            \"__builtins__\": {\"len\": len, \"int\": int, \"str\": str, \"float\": float},\n",
    "            \"np\": np,\n",
    "        }\n",
    "        return bool(eval(expr, allowed_globals, ctx))\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def _apply_translation(value_map, row_ctx):\n",
    "    \"\"\"\n",
    "    value_map pode ser:\n",
    "      - dict simples {orig: dest} (pode conter 'default')\n",
    "      - dict com 'conditions' (lista de {expr, value}) e opcional 'default'\n",
    "    Retorna (valor_traduzido, matched_bool)\n",
    "    \"\"\"\n",
    "    if isinstance(value_map, dict) and \"conditions\" in value_map:\n",
    "        for cond in value_map[\"conditions\"]:\n",
    "            expr = cond.get(\"expr\", \"\")\n",
    "            val = cond.get(\"value\", np.nan)\n",
    "            if expr and _safe_eval_expr(expr, row_ctx):\n",
    "                return val, True\n",
    "        # nenhum matched -> usa default se houver\n",
    "        if \"default\" in value_map:\n",
    "            return value_map[\"default\"], True\n",
    "        return np.nan, False\n",
    "\n",
    "    # mapeamento direto (sem 'conditions'):\n",
    "    if isinstance(value_map, dict):\n",
    "        key = row_ctx.get(\"z_flag\", np.nan)\n",
    "        if key in value_map:\n",
    "            return value_map[key], True\n",
    "        # Se não houver chave correspondente, mas existir 'default', use-o\n",
    "        if \"default\" in value_map:\n",
    "            return value_map[\"default\"], True\n",
    "        return np.nan, False\n",
    "\n",
    "    return np.nan, False\n",
    "\n",
    "def validate_row(row):\n",
    "    survey = row.get(\"survey\", None)\n",
    "\n",
    "    # construir contexto com None -> np.nan, para evitar erros de comparação\n",
    "    ctx = {}\n",
    "    for k, v in row.items():\n",
    "        ctx[k] = (np.nan if v is None else v)\n",
    "\n",
    "    # Casos especiais (CANDELS e NED): regra contínua 0..1 e type herdado\n",
    "    if survey in (\"CANDELS\", \"NED\"):\n",
    "        x = row.get(\"z_flag\", np.nan)\n",
    "        # z_flag esperado:\n",
    "        if x == 0.0:\n",
    "            z_expected = 0.0\n",
    "        elif (isinstance(x, (float, int))) and (0.0 < x < 0.7):\n",
    "            z_expected = 1.0\n",
    "        elif (isinstance(x, (float, int))) and (0.7 <= x < 0.9):\n",
    "            z_expected = 2.0\n",
    "        elif (isinstance(x, (float, int))) and (0.9 <= x < 0.99):\n",
    "            z_expected = 3.0\n",
    "        elif (isinstance(x, (float, int))) and (0.99 <= x <= 1.0):\n",
    "            z_expected = 4.0\n",
    "        else:\n",
    "            z_expected = np.nan\n",
    "\n",
    "        # type_expected é o próprio 'type' da linha\n",
    "        type_expected = row.get(\"instrument_type\", np.nan)\n",
    "        return z_expected, type_expected\n",
    "\n",
    "    # Regras gerais dos surveys\n",
    "    rules = translation_rules.get(survey, None)\n",
    "    if rules is None:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    # z_flag_homogenized esperado\n",
    "    z_rules = rules.get(\"z_flag_translation\", None)\n",
    "    if z_rules is None:\n",
    "        z_expected = np.nan\n",
    "    else:\n",
    "        z_expected, _ = _apply_translation(z_rules, ctx)\n",
    "\n",
    "    # instrument_type_homogenized esperado\n",
    "    t_rules = rules.get(\"instrument_type_translation\", None)\n",
    "    if t_rules is None:\n",
    "        type_expected = np.nan\n",
    "    else:\n",
    "        if isinstance(t_rules, dict) and (\"conditions\" in t_rules or \"default\" in t_rules):\n",
    "            type_expected, matched = _apply_translation(t_rules, ctx)\n",
    "        else:\n",
    "            type_expected, matched = _apply_translation(t_rules, ctx)\n",
    "\n",
    "\n",
    "    return z_expected, type_expected\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# VALIDATE TRANSLATIONS IN TEMP FILES\n",
    "# =========================================================\n",
    "merged_files = glob.glob(os.path.join(prepared_temp_dir, \"prepared*/*.parquet\"))\n",
    "merged_files = [f for f in merged_files if \"pipeline_sample\" not in f]\n",
    "\n",
    "if not merged_files:\n",
    "    print(\"⚠️ No prepared parquet files found for validation.\")\n",
    "else:\n",
    "    issues = []\n",
    "    \n",
    "    for merged_file in merged_files:\n",
    "        print(f\"🔍 Validating {merged_file}\")\n",
    "        df = pd.read_parquet(merged_file)\n",
    "    \n",
    "        for _, row in df.iterrows():\n",
    "            z_exp, type_exp = validate_row(row)\n",
    "    \n",
    "            if not (pd.isna(z_exp) and pd.isna(row[\"z_flag_homogenized\"])) and z_exp != row[\"z_flag_homogenized\"]:\n",
    "                issue = row.to_dict()\n",
    "                issue[\"field\"] = \"z_flag_homogenized\"\n",
    "                issue[\"expected\"] = z_exp\n",
    "                issue[\"found\"] = row[\"z_flag_homogenized\"]\n",
    "                issues.append(issue)\n",
    "    \n",
    "            if not (pd.isna(type_exp) and pd.isna(row[\"instrument_type_homogenized\"])) and type_exp != row[\"instrument_type_homogenized\"]:\n",
    "                issue = row.to_dict()\n",
    "                issue[\"field\"] = \"instrument_type_homogenized\"\n",
    "                issue[\"expected\"] = type_exp\n",
    "                issue[\"found\"] = row[\"instrument_type_homogenized\"]\n",
    "                issues.append(issue)\n",
    "    \n",
    "    if issues:\n",
    "        issues_df = pd.DataFrame(issues)\n",
    "        display(issues_df)\n",
    "        print(f\"⚠️ {len(issues)} mismatches found!\")\n",
    "    else:\n",
    "        print(\"✅ All homogenized fields match the expected values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede0adcb-e34d-4e81-90e1-8079773eedb6",
   "metadata": {},
   "source": [
    "# Time Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417dc417-cee6-45ba-8306-952ac9bf03f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "log_path = \"process001/process_info/pipeline.log\"\n",
    "INIT_LEFT_PAD_S = 3\n",
    "\n",
    "# ---------- Regex ----------\n",
    "TS = r\"(?P<ts>\\d{4}-\\d{2}-\\d{2}-\\d{2}:\\d{2}:\\d{2}\\.\\d+)\"\n",
    "PH = r\"(?P<ph>START|END)\"\n",
    "\n",
    "# Fases macro da coluna \"stage\" (3ª coluna): preparation, automatch, crossmatch, deduplication, consolidation, register\n",
    "PHASES = r\"(?:preparation|automatch|crossmatch|deduplication|consolidation|register)\"\n",
    "RE_PHASE = re.compile(\n",
    "    fr\"{TS}\\s*\\|\\s*INFO\\s*\\|\\s*(?P<phase>{PHASES})\\s*\\|\\s*crc\\s*\\|\\s*{PH}\\s+(?P<msg>.*)$\"\n",
    ")\n",
    "\n",
    "# init (bootstrap)\n",
    "RE_INIT = re.compile(fr\"{TS}\\s*\\|\\s*INFO\\s*\\|\\s*init\\s*\\|\\s*crc\\s*\\|\\s*{PH}\\s+init:\", re.X)\n",
    "\n",
    "# prepare_catalog (produto)\n",
    "RE_PREPARE = re.compile(\n",
    "    fr\"{TS}\\s*\\|\\s*INFO\\s*\\|\\s*preparation\\s*\\|\\s*crc\\.specz\\s*\\|\\s*{PH}\\s+prepare_catalog\\s+product=(?P<name>[\\w.\\-\\d]+)\",\n",
    "    re.X,\n",
    ")\n",
    "\n",
    "# automatch (artifact)\n",
    "RE_AUTOMATCH = re.compile(\n",
    "    fr\"{TS}\\s*\\|\\s*INFO\\s*\\|\\s*automatch\\s*\\|\\s*crc\\.crossmatch_auto\\s*\\|\\s*{PH}\\s+automatch:\\s+artifact=(?P<name>[\\w\\.\\-\\d]+)\",\n",
    "    re.X,\n",
    ")\n",
    "\n",
    "# crossmatch (step)\n",
    "RE_XMATCH = re.compile(\n",
    "    fr\"{TS}\\s*\\|\\s*INFO\\s*\\|\\s*crossmatch\\s*\\|\\s*crc\\.crossmatch\\s*\\|\\s*{PH}\\s+crossmatch_update_compared_to:\\s+step=(?P<step>\\d+)\",\n",
    "    re.X,\n",
    ")\n",
    "\n",
    "def parse_ts(s: str) -> datetime:\n",
    "    return datetime.strptime(s, \"%Y-%m-%d-%H:%M:%S.%f\")\n",
    "\n",
    "# ---------- Varredura ----------\n",
    "start_times, end_times = {}, {}\n",
    "\n",
    "def reg(task_type: str, ident: str, ts: datetime, ph: str):\n",
    "    key = f\"{task_type}|{ident}\"\n",
    "    if ph == \"START\":\n",
    "        if key not in start_times or ts < start_times[key]:\n",
    "            start_times[key] = ts\n",
    "    else:\n",
    "        if key not in end_times or ts > end_times[key]:\n",
    "            end_times[key] = ts\n",
    "\n",
    "if not os.path.exists(log_path):\n",
    "    raise FileNotFoundError(log_path)\n",
    "\n",
    "with open(log_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    for line in f:\n",
    "        # INIT (específico)\n",
    "        m = RE_INIT.search(line)\n",
    "        if m:\n",
    "            ts = parse_ts(m.group(\"ts\")); ph = m.group(\"ph\")\n",
    "            reg(\"init\", \"init\", ts, ph)\n",
    "            continue\n",
    "\n",
    "        # PREPARE por produto (específico)\n",
    "        m = RE_PREPARE.search(line)\n",
    "        if m:\n",
    "            ts = parse_ts(m.group(\"ts\")); ph = m.group(\"ph\")\n",
    "            reg(\"prepare_catalog\", m.group(\"name\"), ts, ph)\n",
    "            continue\n",
    "\n",
    "        # AUTOMATCH por artifact (específico)\n",
    "        m = RE_AUTOMATCH.search(line)\n",
    "        if m:\n",
    "            ts = parse_ts(m.group(\"ts\")); ph = m.group(\"ph\")\n",
    "            reg(\"automatch\", m.group(\"name\"), ts, ph)\n",
    "            continue\n",
    "\n",
    "        # CROSSMATCH step=N (específico)\n",
    "        m = RE_XMATCH.search(line)\n",
    "        if m:\n",
    "            ts = parse_ts(m.group(\"ts\")); ph = m.group(\"ph\")\n",
    "            reg(\"crossmatch\", f\"step{int(m.group('step')):02d}\", ts, ph)\n",
    "            continue\n",
    "\n",
    "        # Fase macro (genérica; por último!)\n",
    "        m = RE_PHASE.search(line)\n",
    "        if m:\n",
    "            ts = parse_ts(m.group(\"ts\")); ph = m.group(\"ph\")\n",
    "            phase = m.group(\"phase\")\n",
    "            reg(f\"{phase}_phase\", phase, ts, ph)\n",
    "            continue\n",
    "\n",
    "# ---------- Filtra completas ----------\n",
    "all_keys = [k for k in start_times if k in end_times]\n",
    "if not all_keys:\n",
    "    raise RuntimeError(\"Nenhuma tarefa com START e END encontrada no log.\")\n",
    "\n",
    "# estética\n",
    "if \"init|init\" in start_times:\n",
    "    start_times[\"init|init\"] -= timedelta(seconds=INIT_LEFT_PAD_S)\n",
    "\n",
    "# ---------- Ordenação ----------\n",
    "def group_of(key: str) -> str:\n",
    "    return key.split(\"|\", 1)[0]\n",
    "\n",
    "def start_of(key: str) -> datetime:\n",
    "    return start_times[key]\n",
    "\n",
    "def crossmatch_sort_key(key: str):\n",
    "    s = key.split(\"|\", 1)[1].replace(\"step\", \"\")\n",
    "    return int(s) if s.isdigit() else 10**9\n",
    "\n",
    "groups = [\n",
    "    \"init\",\n",
    "    \"preparation_phase\",   # barra macro da fase\n",
    "    \"prepare_catalog\",     # barras por produto\n",
    "    \"automatch_phase\",\n",
    "    \"automatch\",           # barras por artifact\n",
    "    \"crossmatch_phase\",\n",
    "    \"crossmatch\",          # barras por step\n",
    "    \"deduplication_phase\",\n",
    "    \"consolidation_phase\",\n",
    "    \"register_phase\",      # aparece só se existir no log\n",
    "]\n",
    "\n",
    "\n",
    "palette = {\n",
    "    \"init\": \"#1f77b4\",\n",
    "    \"preparation_phase\": \"#ff7f0e\",\n",
    "    \"prepare_catalog\": \"#ffbb78\",\n",
    "    \"automatch_phase\": \"#2ca02c\",\n",
    "    \"automatch\": \"#98df8a\",\n",
    "    \"crossmatch_phase\": \"#d62728\",\n",
    "    \"crossmatch\": \"#ff9896\",\n",
    "    \"deduplication_phase\": \"#9467bd\",\n",
    "    \"consolidation_phase\": \"#8c564b\",\n",
    "    \"register_phase\": \"#e377c2\",\n",
    "}\n",
    "\n",
    "\n",
    "ordered_keys = []\n",
    "for g in groups:\n",
    "    gkeys = [k for k in all_keys if group_of(k) == g]\n",
    "    if not gkeys:\n",
    "        continue\n",
    "    if g == \"crossmatch\":\n",
    "        gkeys = sorted(gkeys, key=crossmatch_sort_key)\n",
    "    else:\n",
    "        gkeys = sorted(gkeys, key=start_of)\n",
    "    ordered_keys.extend(gkeys)\n",
    "\n",
    "# --- Injeta register_phase se não existir ---\n",
    "if not any(k.startswith(\"register_phase|\") for k in start_times):\n",
    "    if ordered_keys:\n",
    "        last_end = max(end_times[k] for k in ordered_keys)\n",
    "    else:\n",
    "        last_end = min(start_times.values())\n",
    "    reg_start = last_end + timedelta(seconds=0.5)\n",
    "    reg_end   = reg_start + timedelta(seconds=1.0)\n",
    "    start_times[\"register_phase|register\"] = reg_start\n",
    "    end_times[\"register_phase|register\"]   = reg_end\n",
    "    ordered_keys.append(\"register_phase|register\")\n",
    "\n",
    "# ---------- Referência temporal ----------\n",
    "t0 = min(start_times[k] for k in ordered_keys)\n",
    "starts = [(start_times[k] - t0).total_seconds() for k in ordered_keys]\n",
    "ends   = [(end_times[k]   - t0).total_seconds() for k in ordered_keys]\n",
    "\n",
    "# ---------- Plot ----------\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "# pular os globais destas três fases\n",
    "skip_globals = {\"preparation_phase\", \"automatch_phase\", \"crossmatch_phase\"}\n",
    "\n",
    "# desenha as barras (apenas uma vez)\n",
    "for i, k in enumerate(ordered_keys):\n",
    "    g = group_of(k)\n",
    "    if g in skip_globals:\n",
    "        continue  # não desenha as barras globais dessas três fases\n",
    "\n",
    "    c  = palette.get(g, \"#444444\")\n",
    "    lw = 4 if g.endswith(\"_phase\") else 2  # fases globais restantes (dedup/consolid/register) ficam mais grossas\n",
    "    ax.hlines(y=i, xmin=starts[i], xmax=ends[i], colors=c, linewidth=lw)\n",
    "    ax.scatter([starts[i], ends[i]], [i, i], s=14, color=c, zorder=3)\n",
    "\n",
    "# tira os labels default do eixo Y\n",
    "ax.set_yticks(range(len(ordered_keys)))\n",
    "ax.set_yticklabels([\"\"] * len(ordered_keys))\n",
    "\n",
    "# adiciona só um label por bloco, no centro\n",
    "def add_block_label(prefix, text):\n",
    "    idxs = [i for i, k in enumerate(ordered_keys) if k.startswith(prefix)]\n",
    "    if idxs:\n",
    "        mid = (min(idxs) + max(idxs)) / 2\n",
    "        ax.text(-5, mid, text, va=\"center\", ha=\"right\", fontsize=10, fontweight=\"bold\")\n",
    "\n",
    "add_block_label(\"init\",                \"init\")\n",
    "add_block_label(\"prepare_catalog\", \"preparation\")\n",
    "add_block_label(\"automatch\",       \"automatch\")\n",
    "add_block_label(\"crossmatch\",      \"crossmatch\")\n",
    "add_block_label(\"deduplication_phase\", \"deduplication\")\n",
    "add_block_label(\"consolidation_phase\", \"consolidation\")\n",
    "add_block_label(\"register_phase\",      \"register\")\n",
    "\n",
    "\n",
    "# eixo X e margens (inclui espaço à esquerda para os rótulos em x=-5)\n",
    "xmax = max(ends) if ends else 1.0\n",
    "ax.set_xlim(-6, xmax * 1.02)\n",
    "ax.set_xlabel(\"Time (s)\", fontsize=12)\n",
    "ax.grid(True, linestyle=\"--\", alpha=0.3, axis=\"x\")\n",
    "ax.set_title(\"CRC – Time Profile (pipeline.log)\", fontsize=16)\n",
    "\n",
    "# dá espaço para os rótulos à esquerda sem depender do tight_layout\n",
    "plt.subplots_adjust(left=0.20, right=0.98, top=0.92, bottom=0.08)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_preparation",
   "language": "python",
   "name": "data_preparation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
