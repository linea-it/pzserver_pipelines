{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06d2c6aa-e836-4c37-b67f-b8a828c80590",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351b9448-1cdf-46a1-b07c-b031c3c5f12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921fa07e-c9e5-4ff5-bfa9-ff27115717d6",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c66b946-64d0-4182-aca2-1268f6b3a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# CONFIGURATION SECTION\n",
    "# =========================================================\n",
    "input_paths = [\n",
    "    \"/scratch/users/luigi.silva/speczs-catalogs/processed/2dfgrs_final_release.parquet\",\n",
    "    \"/scratch/users/luigi.silva/speczs-catalogs/processed/2dflens_final_release.parquet\",\n",
    "    \"/scratch/users/luigi.silva/speczs-catalogs/processed/2mrs_v240.parquet\",\n",
    "    \"/scratch/users/luigi.silva/speczs-catalogs/processed/6dfgs_dr3.parquet\",\n",
    "    \"/scratch/users/luigi.silva/speczs-catalogs/processed/desi_dr1_in_lsst_dp1_fields.parquet\",\n",
    "    \"/scratch/users/luigi.silva/speczs-catalogs/processed/jades_dr3.parquet\",\n",
    "    \"/scratch/users/luigi.silva/speczs-catalogs/processed/mosdef_final_release.parquet\",\n",
    "    \"/scratch/users/luigi.silva/speczs-catalogs/processed/ozdes_dr2.parquet\",\n",
    "    \"/scratch/users/luigi.silva/speczs-catalogs/processed/primus_dr1.parquet\",\n",
    "    \"/scratch/users/luigi.silva/speczs-catalogs/processed/vandels_dr4.parquet\",\n",
    "    \"/scratch/users/luigi.silva/speczs-catalogs/processed/vvds_final_release.parquet\"\n",
    "]\n",
    "\n",
    "final_catalog_path = \"/scratch/users/luigi.silva/pzserver_pipelines/combine_redshift_dedup/process003/outputs/crd.parquet\"\n",
    "prepared_temp_dir = \"/scratch/users/luigi.silva/pzserver_pipelines/combine_redshift_dedup/process003/temp/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b1390e-4d78-46dc-a879-93741200e42d",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9d742f-2815-4c78-b471-ed538be842b7",
   "metadata": {},
   "source": [
    "## Validation - Final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db2c2af-86a5-4c2c-abfb-3f304ed3b90d",
   "metadata": {},
   "source": [
    "Counting input and output rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae0ff59-ef63-4ff9-886f-37606a01cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# COUNT INPUT ROWS\n",
    "# =========================================================\n",
    "total_input_rows = 0\n",
    "for path in input_paths:\n",
    "    if os.path.exists(path):\n",
    "        parquet_file = pq.ParquetFile(path)\n",
    "        n_rows = parquet_file.metadata.num_rows\n",
    "        print(f\"{path} -> {n_rows} rows\")\n",
    "        total_input_rows += n_rows\n",
    "    else:\n",
    "        warnings.warn(f\"⚠️ File not found: {path}\")\n",
    "\n",
    "print(f\"✅ Total number of input rows: {total_input_rows}\")\n",
    "\n",
    "# =========================================================\n",
    "# LOAD FINAL MERGED CATALOG\n",
    "# =========================================================\n",
    "if not os.path.exists(final_catalog_path):\n",
    "    raise FileNotFoundError(f\"❌ Final catalog not found: {final_catalog_path}\")\n",
    "\n",
    "df_final = pd.read_parquet(final_catalog_path)\n",
    "print(f\"✅ Total number of rows in final catalog: {len(df_final)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f0918b-8f97-44f5-bf8c-2cb41ba2b9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db02aa8-5dea-41c3-9807-a18308f4b93e",
   "metadata": {},
   "source": [
    "Basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfff02fa-50be-4d05-ae3b-d62ae76df68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332f2bdc-55a9-463c-859b-9dbb1ecd1e57",
   "metadata": {},
   "source": [
    "Counting tie_result values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf326961-1cf0-4587-a47c-bbec4a99dc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[\"tie_result\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cd6ce4-6d28-484f-bf65-68b44085a852",
   "metadata": {},
   "source": [
    "Counting survey values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a2a90c-386c-4904-824a-547509576407",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[\"survey\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99e8dd0-f6cc-4310-a896-fba216515967",
   "metadata": {},
   "source": [
    "Checking the percentage of unsolved objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818d2df1-3df5-45a3-a1bb-217a2925c591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of objects\n",
    "total_all = len(df_final)\n",
    "\n",
    "# Filter objects that were compared (compared_to is not null or empty)\n",
    "mask_compared = df_final[\"compared_to\"].notna() & (df_final[\"compared_to\"] != \"\")\n",
    "df_compared = df_final[mask_compared]\n",
    "\n",
    "# Count how many have tie_result == 2\n",
    "count_tie2 = (df_final[\"tie_result\"] == 2).sum()\n",
    "count_tie2_compared = (df_compared[\"tie_result\"] == 2).sum()\n",
    "\n",
    "# Percentages\n",
    "percent_all = (count_tie2 / total_all) * 100 if total_all > 0 else 0\n",
    "percent_compared = (count_tie2_compared / len(df_compared)) * 100 if len(df_compared) > 0 else 0\n",
    "\n",
    "# Formatted print\n",
    "print(f\"📊 tie_result == 2 represents:\")\n",
    "print(f\"  • {percent_all:.2f}% of the total ({count_tie2} out of {total_all})\")\n",
    "print(f\"  • {percent_compared:.2f}% of the compared objects ({count_tie2_compared} out of {len(df_compared)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220d3621-1cf4-4aa1-94f8-6a6f7dfb5985",
   "metadata": {},
   "source": [
    "Doing the validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6e2afd-890c-466a-a119-442d9230e607",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# =========================================================\n",
    "# ANALYZE GROUPS BY COMPARED_TO\n",
    "# =========================================================\n",
    "threshold = 0.0005\n",
    "max_groups = 20000  # Set to a number for debugging (e.g., 50)\n",
    "\n",
    "desired_order = [\n",
    "    \"CRD_ID\", \"id\", \"ra\", \"dec\", \"z\", \"z_flag\", \"z_err\", \"type\", \"survey\", \"source\",\n",
    "    \"z_flag_homogenized\", \"instrument_type_homogenized\", \"tie_result\", \"compared_to\", \"role\"\n",
    "]\n",
    "\n",
    "df_final = df_final[\n",
    "    (df_final[\"compared_to\"].notnull()) &\n",
    "    (df_final[\"compared_to\"] != \"\")\n",
    "]\n",
    "print(f\"✅ Number of rows with non-empty compared_to: {len(df_final)}\")\n",
    "\n",
    "group_cases = {\n",
    "    \"CASE1_small_same\": [],\n",
    "    \"CASE1_small_diff\": [],\n",
    "    \"CASE1_large_same\": [],\n",
    "    \"CASE1_large_diff\": [],\n",
    "    \"CASE2_small_same\": [],\n",
    "    \"CASE2_small_diff\": [],\n",
    "    \"CASE2_large_same\": [],\n",
    "    \"CASE2_large_diff\": [],\n",
    "    \"TIE_FLAG_TYPE_BREAK_PAIR\": [],\n",
    "    \"TIE_FLAG_TYPE_BREAK_GROUP\": [],\n",
    "    \"SAME_FLAG_DIFF_TYPE\": []\n",
    "}\n",
    "\n",
    "processed_groups = 0\n",
    "seen_groups = set()\n",
    "\n",
    "for idx, row in df_final.iterrows():\n",
    "    if max_groups is not None and processed_groups >= max_groups:\n",
    "        break\n",
    "\n",
    "    group_ids = tuple(sorted([row[\"CRD_ID\"]] + row[\"compared_to\"].split(\",\")))\n",
    "    if group_ids in seen_groups:\n",
    "        continue\n",
    "    seen_groups.add(group_ids)\n",
    "\n",
    "    group_df = df_final[df_final[\"CRD_ID\"].isin(group_ids)].copy()\n",
    "    if len(group_df) < 2:\n",
    "        continue\n",
    "\n",
    "    group_df[\"role\"] = np.where(group_df[\"CRD_ID\"] == row[\"CRD_ID\"], \"principal\", \"compared\")\n",
    "\n",
    "    z_vals = group_df[\"z\"].to_numpy()\n",
    "    surveys = group_df[\"survey\"].values\n",
    "\n",
    "    delta_z_matrix = np.abs(z_vals[:, None] - z_vals[None, :])\n",
    "    pairwise_dz = delta_z_matrix[np.triu_indices(len(z_vals), k=1)]\n",
    "\n",
    "    max_delta_z = np.max(pairwise_dz)\n",
    "    all_pairs_below_thresh = np.all(pairwise_dz <= threshold)\n",
    "    same_survey = len(set(surveys)) == 1\n",
    "\n",
    "    # Classify group\n",
    "    if len(group_df) == 2:\n",
    "        key = \"CASE1_small_same\" if max_delta_z <= threshold and same_survey else \\\n",
    "              \"CASE1_small_diff\" if max_delta_z <= threshold else \\\n",
    "              \"CASE1_large_same\" if same_survey else \"CASE1_large_diff\"\n",
    "    else:\n",
    "        key = \"CASE2_small_same\" if all_pairs_below_thresh and same_survey else \\\n",
    "              \"CASE2_small_diff\" if all_pairs_below_thresh else \\\n",
    "              \"CASE2_large_same\" if same_survey else \"CASE2_large_diff\"\n",
    "\n",
    "    # Reorder columns\n",
    "    all_columns = list(group_df.columns)\n",
    "    ordered_columns = desired_order + [col for col in all_columns if col not in desired_order]\n",
    "    group_df = group_df.reindex(columns=ordered_columns)\n",
    "\n",
    "    group_cases[key].append(group_df)\n",
    "\n",
    "    # Additional logic\n",
    "    flags = set(group_df[\"z_flag_homogenized\"].dropna())\n",
    "    types = set(group_df[\"instrument_type_homogenized\"].dropna())\n",
    "    surveys_in_group = set(group_df[\"survey\"].dropna())\n",
    "\n",
    "    if len(surveys_in_group) > 1 and len(flags) == 1 and len(types) > 1:\n",
    "        case_key = \"TIE_FLAG_TYPE_BREAK_PAIR\" if len(group_df) == 2 else \"TIE_FLAG_TYPE_BREAK_GROUP\"\n",
    "        group_cases[case_key].append(group_df)\n",
    "\n",
    "    if len(flags) == 1 and len(types) > 1:\n",
    "        group_cases[\"SAME_FLAG_DIFF_TYPE\"].append(group_df)\n",
    "\n",
    "    processed_groups += 1\n",
    "\n",
    "print(f\"✅ Processed {processed_groups} unique groups.\")\n",
    "\n",
    "# Case descriptions\n",
    "case_descriptions = {\n",
    "    \"CASE1_small_same\": f\"pair with delta_z <= {threshold} from same survey\",\n",
    "    \"CASE1_small_diff\": f\"pair with delta_z <= {threshold} from different surveys\",\n",
    "    \"CASE1_large_same\": f\"pair with delta_z > {threshold} from same survey\",\n",
    "    \"CASE1_large_diff\": f\"pair with delta_z > {threshold} from different surveys\",\n",
    "    \"CASE2_small_same\": f\"group with all delta_z <= {threshold} from same survey\",\n",
    "    \"CASE2_small_diff\": f\"group with all delta_z <= {threshold} from different surveys\",\n",
    "    \"CASE2_large_same\": f\"group with some delta_z > {threshold} from same survey\",\n",
    "    \"CASE2_large_diff\": f\"group with some delta_z > {threshold} from different surveys\",\n",
    "    \"TIE_FLAG_TYPE_BREAK_PAIR\": \"pair with equal z_flag_homogenized, different instrument_type_homogenized, and different surveys\",\n",
    "    \"TIE_FLAG_TYPE_BREAK_GROUP\": \"group with equal z_flag_homogenized, different instrument_type_homogenized, and different surveys\",\n",
    "    \"SAME_FLAG_DIFF_TYPE\": \"group with same z_flag_homogenized but at least one differing instrument_type_homogenized\"\n",
    "}\n",
    "\n",
    "# Display up to 5 examples per case\n",
    "for case_name, groups in group_cases.items():\n",
    "    if not groups:\n",
    "        continue\n",
    "    print(f\"\\n📌 Showing examples of {case_descriptions[case_name]} \"\n",
    "          f\"({len(groups)} groups found):\")\n",
    "    for group in groups[:5]:\n",
    "        display(group)\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801271a1-eeb4-402d-a97c-46de5cb47376",
   "metadata": {},
   "source": [
    "## Validation - Prepared Catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c38638-040b-43cc-9c0b-fb22ba0e0dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# VALIDATE TRANSLATIONS IN TEMP FILES\n",
    "# =========================================================\n",
    "merged_files = glob.glob(os.path.join(prepared_temp_dir, \"prepared*/*.parquet\"))\n",
    "if not merged_files:\n",
    "    print(\"⚠️ No prepared parquet files found for validation.\")\n",
    "else:\n",
    "    def validate_row(row):\n",
    "        survey = row[\"survey\"]\n",
    "        z_flag = row.get(\"z_flag\", None)\n",
    "        z_err = row.get(\"z_err\", None)\n",
    "        zcat_primary = row.get(\"ZCAT_PRIMARY\", None)\n",
    "    \n",
    "        z_expected = np.nan\n",
    "        type_expected = np.nan\n",
    "    \n",
    "        if survey == \"2DFGRS\":\n",
    "            type_expected = \"s\"\n",
    "            z_expected = {1: 0, 2: 1, 3: 3, 4: 4, 5: 4}.get(z_flag, np.nan)\n",
    "    \n",
    "        elif survey == \"2DFLENS\":\n",
    "            type_expected = \"s\"\n",
    "            z_expected = {1: 0, 2: 1, 3: 3, 4: 4, 6: 6}.get(z_flag, np.nan)\n",
    "    \n",
    "        elif survey == \"2MRS\":\n",
    "            type_expected = \"s\"\n",
    "            if z_err == 0:\n",
    "                z_expected = 3\n",
    "            elif z_err is not None and 0 < z_err < 0.0005:\n",
    "                z_expected = 4\n",
    "            elif z_err is not None and z_err >= 0.0005:\n",
    "                z_expected = 3\n",
    "    \n",
    "        elif survey == \"6DFGS\":\n",
    "            type_expected = \"s\"\n",
    "            z_expected = {1: 0, 2: 1, 3: 3, 4: 4, 6: 6}.get(z_flag, np.nan)\n",
    "    \n",
    "        elif survey == \"DESI\":\n",
    "            type_expected = \"s\"\n",
    "            if zcat_primary is not True:\n",
    "                z_expected = 0\n",
    "            elif z_flag != 0 and zcat_primary is True:\n",
    "                z_expected = 1\n",
    "            elif z_flag == 0 and zcat_primary is True:\n",
    "                if z_err is not None and z_err < 0.0005:\n",
    "                    z_expected = 4\n",
    "                elif z_err is not None and z_err >= 0.0005:\n",
    "                    z_expected = 3\n",
    "    \n",
    "        elif survey == \"JADES\":\n",
    "            type_expected = \"s\"\n",
    "            z_expected = {0: 0, 1: 1, 2: 2, 3: 3, 4: 4}.get(z_flag, np.nan)\n",
    "    \n",
    "        elif survey == \"MOSDEF\":\n",
    "            type_expected = \"s\"\n",
    "            z_expected = {\n",
    "                0: 0, 1: 0, 2: 1, 3: 1, 4: 2, 5: 2, 6: 3, 7: 4\n",
    "            }.get(z_flag, np.nan)\n",
    "    \n",
    "        elif survey == \"OZDES\":\n",
    "            type_expected = \"s\"\n",
    "            z_expected = {1: 0, 2: 1, 3: 3, 4: 4, 6: 6}.get(z_flag, np.nan)\n",
    "    \n",
    "        elif survey == \"PRIMUS\":\n",
    "            type_expected = \"g\"\n",
    "            z_expected = {-1: 0, 2: 1, 3: 2, 4: 3}.get(z_flag, np.nan)\n",
    "    \n",
    "        elif survey == \"VANDELS\":\n",
    "            type_expected = \"s\"\n",
    "            vandels_map = {\n",
    "                0: 0, 1: 1, 2: 2, 3: 4, 4: 4, 9: 3,\n",
    "                10: 0, 11: 1, 12: 2, 13: 4, 14: 4, 19: 3,\n",
    "                20: 0, 21: 1, 22: 2, 23: 4, 24: 4, 29: 3,\n",
    "                210: 0, 211: 1, 212: 2, 213: 4, 214: 4, 219: 3\n",
    "            }\n",
    "            z_expected = vandels_map.get(z_flag, np.nan)\n",
    "    \n",
    "        elif survey == \"VVDS\":\n",
    "            type_expected = \"s\"\n",
    "            vvds_map = {\n",
    "                0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 9: 2,\n",
    "                10: 0, 11: 1, 12: 2, 13: 3, 14: 4, 19: 2,\n",
    "                20: 0, 21: 1, 22: 2, 23: 3, 24: 4, 29: 2,\n",
    "                210: 0, 211: 1, 212: 2, 213: 3, 214: 4, 219: 2\n",
    "            }\n",
    "            z_expected = vvds_map.get(z_flag, np.nan)\n",
    "    \n",
    "        return z_expected, type_expected\n",
    "\n",
    "\n",
    "    issues = []\n",
    "    \n",
    "    for merged_file in merged_files:\n",
    "        print(f\"🔍 Validating {merged_file}\")\n",
    "        df = pd.read_parquet(merged_file)\n",
    "    \n",
    "        for _, row in df.iterrows():\n",
    "            z_exp, type_exp = validate_row(row)\n",
    "    \n",
    "            if not (pd.isna(z_exp) and pd.isna(row[\"z_flag_homogenized\"])) and z_exp != row[\"z_flag_homogenized\"]:\n",
    "                issue = row.to_dict()\n",
    "                issue[\"field\"] = \"z_flag_homogenized\"\n",
    "                issue[\"expected\"] = z_exp\n",
    "                issue[\"found\"] = row[\"z_flag_homogenized\"]\n",
    "                issues.append(issue)\n",
    "    \n",
    "            if not (pd.isna(type_exp) and pd.isna(row[\"instrument_type_homogenized\"])) and type_exp != row[\"instrument_type_homogenized\"]:\n",
    "                issue = row.to_dict()\n",
    "                issue[\"field\"] = \"instrument_type_homogenized\"\n",
    "                issue[\"expected\"] = type_exp\n",
    "                issue[\"found\"] = row[\"instrument_type_homogenized\"]\n",
    "                issues.append(issue)\n",
    "    \n",
    "    if issues:\n",
    "        issues_df = pd.DataFrame(issues)\n",
    "        display(issues_df)\n",
    "        print(f\"⚠️ {len(issues)} mismatches found!\")\n",
    "    else:\n",
    "        print(\"✅ All homogenized fields match the expected values.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipe_csc",
   "language": "python",
   "name": "pipe_csc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
