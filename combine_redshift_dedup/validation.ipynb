{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06d2c6aa-e836-4c37-b67f-b8a828c80590",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351b9448-1cdf-46a1-b07c-b031c3c5f12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "user = getpass.getuser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921fa07e-c9e5-4ff5-bfa9-ff27115717d6",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c66b946-64d0-4182-aca2-1268f6b3a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# CONFIGURATION SECTION\n",
    "# =========================================================\n",
    "#input_paths = [\n",
    "#    f\"/scratch/users/{user}/speczs-catalogs/processed/2dfgrs_final_release.parquet\",\n",
    "#    f\"/scratch/users/{user}/speczs-catalogs/processed/2dflens_final_release.parquet\",\n",
    "#    f\"/scratch/users/{user}/speczs-catalogs/processed/2mrs_v240.parquet\",\n",
    "#    f\"/scratch/users/luigi.silva/speczs-catalogs/processed/3dhst_v4.1.5.parquet\",\n",
    "#    f\"/scratch/users/{user}/speczs-catalogs/processed/6dfgs_dr3.parquet\",\n",
    "#    f\"/scratch/users/luigi.silva/speczs-catalogs/processed/astrodeep_jwst.parquet\",\n",
    "#    f\"/scratch/users/luigi.silva/speczs-catalogs/processed/astrodeep-gs43.parquet\",\n",
    "#    f\"/scratch/users/{user}/speczs-catalogs/processed/desi_dr1_in_lsst_dp1_fields.parquet\",\n",
    "#    f\"/scratch/users/{user}/speczs-catalogs/processed/jades_dr3.parquet\",\n",
    "#    f\"/scratch/users/{user}/speczs-catalogs/processed/mosdef_final_release.parquet\",\n",
    "#    f\"/scratch/users/{user}/speczs-catalogs/processed/ozdes_dr2.parquet\",\n",
    "#    f\"/scratch/users/{user}/speczs-catalogs/processed/primus_dr1.parquet\",\n",
    "#    f\"/scratch/users/{user}/speczs-catalogs/processed/vandels_dr4.parquet\",\n",
    "#    f\"/scratch/users/luigi.silva/speczs-catalogs/processed/vlt_vimos_v2.0.1.parquet\",\n",
    "#    f\"/scratch/users/luigi.silva/speczs-catalogs/processed/vuds_dr1.parquet\",\n",
    "#    f\"/scratch/users/{user}/speczs-catalogs/processed/vvds_final_release.parquet\",\n",
    "#    f\"/scratch/users/luigi.silva/speczs-catalogs/johns-catalogs/z_cat_CANDELS_clean_sitcomtn-154.parquet\",\n",
    "#    f\"/scratch/users/luigi.silva/speczs-catalogs/johns-catalogs/z_cat_NED_clean_sitcomtn-154.parquet\",\n",
    "#]\n",
    "\n",
    "input_paths = glob.glob('test_data/*.parquet')\n",
    "\n",
    "final_catalog_path = f\"./process001/outputs/crd.parquet\"\n",
    "prepared_temp_dir = f\"./process001/temp/\"\n",
    "\n",
    "combine_mode = \"concatenate_and_mark_duplicates\" # Options: \"concatenate\", \"concatenate_and_mark_duplicates\", or \"concatenate_and_remove_duplicates\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b1390e-4d78-46dc-a879-93741200e42d",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9d742f-2815-4c78-b471-ed538be842b7",
   "metadata": {},
   "source": [
    "## Basic Info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db2c2af-86a5-4c2c-abfb-3f304ed3b90d",
   "metadata": {},
   "source": [
    "Counting input and output rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae0ff59-ef63-4ff9-886f-37606a01cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# COUNT INPUT ROWS\n",
    "# =========================================================\n",
    "total_input_rows = 0\n",
    "for path in input_paths:\n",
    "    if os.path.exists(path):\n",
    "        parquet_file = pq.ParquetFile(path)\n",
    "        n_rows = parquet_file.metadata.num_rows\n",
    "        print(f\"{path} -> {n_rows} rows\")\n",
    "        total_input_rows += n_rows\n",
    "    else:\n",
    "        warnings.warn(f\"⚠️ File not found: {path}\")\n",
    "\n",
    "print(f\"✅ Total number of input rows: {total_input_rows}\")\n",
    "\n",
    "# =========================================================\n",
    "# LOAD FINAL MERGED CATALOG\n",
    "# =========================================================\n",
    "if not os.path.exists(final_catalog_path):\n",
    "    raise FileNotFoundError(f\"❌ Final catalog not found: {final_catalog_path}\")\n",
    "\n",
    "df_final = pd.read_parquet(final_catalog_path)\n",
    "print(f\"✅ Total number of rows in final catalog: {len(df_final)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d55c9e8-c4e8-4c7b-a057-8f3fd80471c0",
   "metadata": {},
   "source": [
    "Printing the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46685e01-a0c4-4da7-b5cf-3e7a43794889",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed728553-feda-4264-aee8-482e202f6443",
   "metadata": {},
   "source": [
    "Dataframe columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6a85f2-2deb-419b-84f0-893ccbf4ce3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4c7fcd-64de-489a-8254-f83e08a2abbc",
   "metadata": {},
   "source": [
    "Dataframe columns types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba9d0d0-c23e-41d4-a01c-3e53161f01eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db02aa8-5dea-41c3-9807-a18308f4b93e",
   "metadata": {},
   "source": [
    "Basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfff02fa-50be-4d05-ae3b-d62ae76df68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332f2bdc-55a9-463c-859b-9dbb1ecd1e57",
   "metadata": {},
   "source": [
    "Counting tie_result values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf326961-1cf0-4587-a47c-bbec4a99dc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "if combine_mode != \"concatenate\":\n",
    "    print(df_final[\"tie_result\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cd6ce4-6d28-484f-bf65-68b44085a852",
   "metadata": {},
   "source": [
    "Counting source values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a2a90c-386c-4904-824a-547509576407",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[\"source\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99e8dd0-f6cc-4310-a896-fba216515967",
   "metadata": {},
   "source": [
    "Checking the percentage of unsolved objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818d2df1-3df5-45a3-a1bb-217a2925c591",
   "metadata": {},
   "outputs": [],
   "source": [
    "if combine_mode != \"concatenate\":\n",
    "    # Total number of objects\n",
    "    total_all = len(df_final)\n",
    "    \n",
    "    # Filter objects that were compared (compared_to is not null or empty)\n",
    "    mask_compared = df_final[\"compared_to\"].notna() & (df_final[\"compared_to\"] != \"\")\n",
    "    df_compared = df_final[mask_compared]\n",
    "    \n",
    "    # Count how many have tie_result == 2\n",
    "    count_tie2 = (df_final[\"tie_result\"] == 2).sum()\n",
    "    count_tie2_compared = (df_compared[\"tie_result\"] == 2).sum()\n",
    "    \n",
    "    # Percentages\n",
    "    percent_all = (count_tie2 / total_all) * 100 if total_all > 0 else 0\n",
    "    percent_compared = (count_tie2_compared / len(df_compared)) * 100 if len(df_compared) > 0 else 0\n",
    "    \n",
    "    # Formatted print\n",
    "    print(f\"📊 tie_result == 2 represents:\")\n",
    "    print(f\"  • {percent_all:.2f}% of the total ({count_tie2} out of {total_all})\")\n",
    "    print(f\"  • {percent_compared:.2f}% of the compared objects ({count_tie2_compared} out of {len(df_compared)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19122dc4-9a55-41ff-8c00-2ab72eda2b89",
   "metadata": {},
   "source": [
    "## Individual Catalogs Deduplication Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b87f693-072b-48ea-bf78-e7fad7f351c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"test_data/pipeline_generated_sample.parquet\" in input_paths:\n",
    "    df_final_val = df_final[df_final[\"source\"] != \"019_pipeline_sample\"]\n",
    "else:\n",
    "    df_final_val = df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74320729-c712-4a7a-88ce-549891c2b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import validation_functions as vf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e7d96d-f5e5-4368-b9db-99e8fa689376",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = vf.validate_intra_source_cells_fast(df_final_val, ndp=4, source_col=\"source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0d138e-ab3e-488d-ab95-a36a0ac1ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vf.explain_intra_source_validation_output(\n",
    "    res,\n",
    "    top_k=5,\n",
    "    df_original=df_final_val,   \n",
    "    ndp_used=4,\n",
    "    samples_per_source=2,   \n",
    "    max_sources=5,         \n",
    "    source_col=\"source\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220d3621-1cf4-4aa1-94f8-6a6f7dfb5985",
   "metadata": {},
   "source": [
    "## Cross Catalog Deduplication Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d2e1b6-0f02-4ff9-baab-a029cfce7315",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = vf.validate_tie_results_fast(df_final_val, threshold=0.0005, max_groups=20000, include_rows=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246692ac-5c4a-465c-8802-2ab6831b6e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vf.explain_tie_validation_output(report, show_per_rule=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df7b3a3-d1f0-405e-b28a-b2c6b9a63e1d",
   "metadata": {},
   "source": [
    "## Non-compared Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df988e3a-dda3-43fb-931a-415420204d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vf.render_na_compared_to_validation(df_final_val, show_max=10, assert_if_invalid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1754379f-3e1b-417c-bf27-8a36ce31ed26",
   "metadata": {},
   "source": [
    "## Own Pipeline Product Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9c3797-ca65-474e-9852-ec3ab2f7ecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_parquet(\"test_data/pipeline_generated_sample.parquet\")\n",
    "df_processed = df_final[df_final[\"source\"] == \"019_pipeline_sample\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a98c9d-412d-44f8-bb1e-f720e3ab9146",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = vf.validate_tie_preservation(df_original, df_processed, key=\"CRD_ID\")\n",
    "print(vf.explain_tie_preservation(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f35e40-d969-4e3c-b91c-31bd567318ce",
   "metadata": {},
   "source": [
    "## Manual Validation (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb72123e-ecb3-47b4-bac3-9e131207f02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = vf.analyze_groups_by_compared_to(\n",
    "#    df_final,\n",
    "#    threshold=0.0005,\n",
    "#    max_groups=5000,\n",
    "#    max_examples_per_case=4,\n",
    "#    render=True,\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801271a1-eeb4-402d-a97c-46de5cb47376",
   "metadata": {},
   "source": [
    "## Validation - Prepared Catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c38638-040b-43cc-9c0b-fb22ba0e0dd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dicionário de regras equivalente ao YAML\n",
    "translation_rules = {\n",
    "    \"2DFGRS\": {\n",
    "        \"z_flag_translation\": {1: 0, 2: 1, 3: 3, 4: 4, 5: 4},\n",
    "        \"instrument_type_translation\": {\"default\": \"s\"},\n",
    "    },\n",
    "    \"2DFLENS\": {\n",
    "        \"z_flag_translation\": {1: 0, 2: 1, 3: 3, 4: 4, 6: 6},\n",
    "        \"instrument_type_translation\": {\"default\": \"s\"},\n",
    "    },\n",
    "    \"2MRS\": {\n",
    "        \"z_flag_translation\": {\n",
    "            \"conditions\": [\n",
    "                {\"expr\": \"z_err == 0\", \"value\": 3},\n",
    "                {\"expr\": \"0 < z_err < 0.0005\", \"value\": 4},\n",
    "                {\"expr\": \"z_err >= 0.0005\", \"value\": 3},\n",
    "            ],\n",
    "            \"default\": 0,\n",
    "        },\n",
    "        \"instrument_type_translation\": {\"default\": \"s\"},\n",
    "    },\n",
    "    \"3D-HST\": {\n",
    "        \"z_flag_translation\": {\n",
    "            \"conditions\": [\n",
    "                {\"expr\": \"z_best_s == 0\", \"value\": 6},\n",
    "                {\"expr\": \"z_best_s == 1 and z_spec != -1\", \"value\": 4},\n",
    "                {\"expr\": \"z_best_s == 2 and use_zgrism == 1 and flag1 == 0 and flag2 == 0\", \"value\": 3},\n",
    "                {\"expr\": \"z_best_s == 3 and use_phot == 1\", \"value\": 3},\n",
    "            ],\n",
    "            \"default\": 0,\n",
    "        },\n",
    "        \"instrument_type_translation\": {\n",
    "            \"conditions\": [\n",
    "                {\"expr\": \"z_best_s == 1\", \"value\": \"s\"},\n",
    "                {\"expr\": \"z_best_s == 2\", \"value\": \"g\"},\n",
    "                {\"expr\": \"z_best_s == 3\", \"value\": \"p\"},\n",
    "            ],\n",
    "            \"default\": \"g\",\n",
    "        },\n",
    "    },\n",
    "    \"6DFGS\": {\n",
    "        \"z_flag_translation\": {1: 0, 2: 1, 3: 3, 4: 4, 6: 6},\n",
    "        \"instrument_type_translation\": {\"default\": \"s\"},\n",
    "    },\n",
    "    \"ASTRODEEP\": {\n",
    "        \"z_flag_translation\": {\n",
    "            \"conditions\": [\n",
    "                {\"expr\": \"zspec_survey != '-'\", \"value\": 4},\n",
    "                {\"expr\": \"zspec_survey == '-'\", \"value\": 3},\n",
    "            ],\n",
    "            \"default\": 0,\n",
    "        },\n",
    "        \"instrument_type_translation\": {\n",
    "            \"conditions\": [\n",
    "                {\"expr\": \"zspec_survey != '-'\", \"value\": \"s\"},\n",
    "                {\"expr\": \"zspec_survey == '-'\", \"value\": \"p\"},\n",
    "            ],\n",
    "            \"default\": \"p\",\n",
    "        },\n",
    "    },\n",
    "    \"ASTRODEEP-JWST\": {\n",
    "        \"z_flag_translation\": {\n",
    "            \"conditions\": [\n",
    "                {\"expr\": \"zspec != -99 and z_flag < 400 and (len(str(int(z_flag))) <= 1 or int(str(int(z_flag))[-2]) <= 3)\", \"value\": 4},\n",
    "                {\"expr\": \"zspec == -99 and z_flag < 400 and (len(str(int(z_flag))) <= 1 or int(str(int(z_flag))[-2]) <= 3)\", \"value\": 3},\n",
    "            ],\n",
    "            \"default\": 0,\n",
    "        },\n",
    "        \"instrument_type_translation\": {\n",
    "            \"conditions\": [\n",
    "                {\"expr\": \"zspec != -99\", \"value\": \"s\"},\n",
    "                {\"expr\": \"zspec == -99\", \"value\": \"p\"},\n",
    "            ],\n",
    "            \"default\": \"p\",\n",
    "        },\n",
    "    },\n",
    "    \"DESI\": {\n",
    "        \"z_flag_translation\": {\n",
    "            \"conditions\": [\n",
    "                {\"expr\": \"ZCAT_PRIMARY != True\", \"value\": 0},\n",
    "                {\"expr\": \"z_flag != 0 and ZCAT_PRIMARY == True\", \"value\": 1},\n",
    "                {\"expr\": \"z_flag == 0 and ZCAT_PRIMARY == True and z_err < 0.0005\", \"value\": 4},\n",
    "                {\"expr\": \"z_flag == 0 and ZCAT_PRIMARY == True and z_err >= 0.0005\", \"value\": 3},\n",
    "            ],\n",
    "            \"default\": 0,\n",
    "        },\n",
    "        \"instrument_type_translation\": {\"default\": \"s\"},\n",
    "    },\n",
    "    \"JADES\": {\n",
    "        \"z_flag_translation\": {4: 4, 3: 3, 2: 2, 1: 1, 0: 0},\n",
    "        \"instrument_type_translation\": {\"default\": \"s\"},\n",
    "    },\n",
    "    \"MOSDEF\": {\n",
    "        \"z_flag_translation\": {7: 4, 6: 3, 5: 2, 4: 2, 3: 1, 2: 1, 1: 0, 0: 0},\n",
    "        \"instrument_type_translation\": {\"default\": \"s\"},\n",
    "    },\n",
    "    \"OZDES\": {\n",
    "        \"z_flag_translation\": {1: 0, 2: 1, 3: 3, 4: 4, 6: 6},\n",
    "        \"instrument_type_translation\": {\"default\": \"s\"},\n",
    "    },\n",
    "    \"PRIMUS\": {\n",
    "        \"z_flag_translation\": {-1: 0, 2: 1, 3: 2, 4: 3},\n",
    "        \"instrument_type_translation\": {\"default\": \"g\"},\n",
    "    },\n",
    "    \"VANDELS\": {\n",
    "        \"z_flag_translation\": {\n",
    "            0: 0, 1: 1, 2: 2, 3: 4, 4: 4, 9: 3,\n",
    "            10: 0, 11: 1, 12: 2, 13: 4, 14: 4, 19: 3,\n",
    "            20: 0, 21: 1, 22: 2, 23: 4, 24: 4, 29: 3,\n",
    "            210: 0, 211: 1, 212: 2, 213: 4, 214: 4, 219: 3,\n",
    "        },\n",
    "        \"instrument_type_translation\": {\"default\": \"s\"},\n",
    "    },\n",
    "    \"VIMOS\": {\n",
    "        \"z_flag_translation\": {4: 4, 3: 3, 2: 2, 1: 1, 0: 0},\n",
    "        \"instrument_type_translation\": {\"default\": \"s\"},\n",
    "    },\n",
    "    \"VUDS\": {\n",
    "        \"z_flag_translation\": {\n",
    "            1: 1, 11: 1, 21: 1, 31: 1, 41: 1,\n",
    "            2: 2, 12: 2, 22: 2, 32: 2, 42: 2, 9: 2, 19: 2, 29: 2, 39: 2, 49: 2,\n",
    "            3: 3, 13: 3, 23: 3, 33: 3, 43: 3,\n",
    "            4: 4, 14: 4, 24: 4, 34: 4, 44: 4,\n",
    "        },\n",
    "        \"instrument_type_translation\": {\"default\": \"s\"},\n",
    "    },\n",
    "    \"VVDS\": {\n",
    "        \"z_flag_translation\": {\n",
    "            0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 9: 2,\n",
    "            10: 0, 11: 1, 12: 2, 13: 3, 14: 4, 19: 2,\n",
    "            20: 0, 21: 1, 22: 2, 23: 3, 24: 4, 29: 2,\n",
    "            210: 0, 211: 1, 212: 2, 213: 3, 214: 4, 219: 2,\n",
    "        },\n",
    "        \"instrument_type_translation\": {\"default\": \"s\"},\n",
    "    },\n",
    "\n",
    "    # Special cases using continuous rule and inherited type\n",
    "    \"CANDELS\": {\"_special\": \"CANDELS_NED\"},\n",
    "    \"NED\": {\"_special\": \"CANDELS_NED\"},\n",
    "}\n",
    "\n",
    "def _safe_eval_expr(expr: str, ctx: dict) -> bool:\n",
    "    \"\"\"\n",
    "    Avalia 'expr' usando apenas variáveis do ctx e funções básicas.\n",
    "    Retorna True/False; se der erro, retorna False.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Permitir apenas funções básicas e numpy\n",
    "        allowed_globals = {\n",
    "            \"__builtins__\": {\"len\": len, \"int\": int, \"str\": str, \"float\": float},\n",
    "            \"np\": np,\n",
    "        }\n",
    "        return bool(eval(expr, allowed_globals, ctx))\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def _apply_translation(value_map, row_ctx):\n",
    "    \"\"\"\n",
    "    value_map pode ser:\n",
    "      - dict simples {orig: dest} (pode conter 'default')\n",
    "      - dict com 'conditions' (lista de {expr, value}) e opcional 'default'\n",
    "    Retorna (valor_traduzido, matched_bool)\n",
    "    \"\"\"\n",
    "    if isinstance(value_map, dict) and \"conditions\" in value_map:\n",
    "        for cond in value_map[\"conditions\"]:\n",
    "            expr = cond.get(\"expr\", \"\")\n",
    "            val = cond.get(\"value\", np.nan)\n",
    "            if expr and _safe_eval_expr(expr, row_ctx):\n",
    "                return val, True\n",
    "        # nenhum matched -> usa default se houver\n",
    "        if \"default\" in value_map:\n",
    "            return value_map[\"default\"], True\n",
    "        return np.nan, False\n",
    "\n",
    "    # mapeamento direto (sem 'conditions'):\n",
    "    if isinstance(value_map, dict):\n",
    "        key = row_ctx.get(\"z_flag\", np.nan)\n",
    "        if key in value_map:\n",
    "            return value_map[key], True\n",
    "        # Se não houver chave correspondente, mas existir 'default', use-o\n",
    "        if \"default\" in value_map:\n",
    "            return value_map[\"default\"], True\n",
    "        return np.nan, False\n",
    "\n",
    "    return np.nan, False\n",
    "\n",
    "def validate_row(row):\n",
    "    survey = row.get(\"survey\", None)\n",
    "\n",
    "    # construir contexto com None -> np.nan, para evitar erros de comparação\n",
    "    ctx = {}\n",
    "    for k, v in row.items():\n",
    "        ctx[k] = (np.nan if v is None else v)\n",
    "\n",
    "    # Casos especiais (CANDELS e NED): regra contínua 0..1 e type herdado\n",
    "    if survey in (\"CANDELS\", \"NED\"):\n",
    "        x = row.get(\"z_flag\", np.nan)\n",
    "        # z_flag esperado:\n",
    "        if x == 0.0:\n",
    "            z_expected = 0.0\n",
    "        elif (isinstance(x, (float, int))) and (0.0 < x < 0.7):\n",
    "            z_expected = 1.0\n",
    "        elif (isinstance(x, (float, int))) and (0.7 <= x < 0.9):\n",
    "            z_expected = 2.0\n",
    "        elif (isinstance(x, (float, int))) and (0.9 <= x < 0.99):\n",
    "            z_expected = 3.0\n",
    "        elif (isinstance(x, (float, int))) and (0.99 <= x <= 1.0):\n",
    "            z_expected = 4.0\n",
    "        else:\n",
    "            z_expected = np.nan\n",
    "\n",
    "        # type_expected é o próprio 'type' da linha\n",
    "        type_expected = row.get(\"instrument_type\", np.nan)\n",
    "        return z_expected, type_expected\n",
    "\n",
    "    # Regras gerais dos surveys\n",
    "    rules = translation_rules.get(survey, None)\n",
    "    if rules is None:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    # z_flag_homogenized esperado\n",
    "    z_rules = rules.get(\"z_flag_translation\", None)\n",
    "    if z_rules is None:\n",
    "        z_expected = np.nan\n",
    "    else:\n",
    "        z_expected, _ = _apply_translation(z_rules, ctx)\n",
    "\n",
    "    # instrument_type_homogenized esperado\n",
    "    t_rules = rules.get(\"instrument_type_translation\", None)\n",
    "    if t_rules is None:\n",
    "        type_expected = np.nan\n",
    "    else:\n",
    "        if isinstance(t_rules, dict) and (\"conditions\" in t_rules or \"default\" in t_rules):\n",
    "            type_expected, matched = _apply_translation(t_rules, ctx)\n",
    "        else:\n",
    "            type_expected, matched = _apply_translation(t_rules, ctx)\n",
    "\n",
    "\n",
    "    return z_expected, type_expected\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# VALIDATE TRANSLATIONS IN TEMP FILES\n",
    "# =========================================================\n",
    "merged_files = glob.glob(os.path.join(prepared_temp_dir, \"prepared*/*.parquet\"))\n",
    "merged_files = [f for f in merged_files if \"pipeline_sample\" not in f]\n",
    "\n",
    "if not merged_files:\n",
    "    print(\"⚠️ No prepared parquet files found for validation.\")\n",
    "else:\n",
    "    issues = []\n",
    "    \n",
    "    for merged_file in merged_files:\n",
    "        print(f\"🔍 Validating {merged_file}\")\n",
    "        df = pd.read_parquet(merged_file)\n",
    "    \n",
    "        for _, row in df.iterrows():\n",
    "            z_exp, type_exp = validate_row(row)\n",
    "    \n",
    "            if not (pd.isna(z_exp) and pd.isna(row[\"z_flag_homogenized\"])) and z_exp != row[\"z_flag_homogenized\"]:\n",
    "                issue = row.to_dict()\n",
    "                issue[\"field\"] = \"z_flag_homogenized\"\n",
    "                issue[\"expected\"] = z_exp\n",
    "                issue[\"found\"] = row[\"z_flag_homogenized\"]\n",
    "                issues.append(issue)\n",
    "    \n",
    "            if not (pd.isna(type_exp) and pd.isna(row[\"instrument_type_homogenized\"])) and type_exp != row[\"instrument_type_homogenized\"]:\n",
    "                issue = row.to_dict()\n",
    "                issue[\"field\"] = \"instrument_type_homogenized\"\n",
    "                issue[\"expected\"] = type_exp\n",
    "                issue[\"found\"] = row[\"instrument_type_homogenized\"]\n",
    "                issues.append(issue)\n",
    "    \n",
    "    if issues:\n",
    "        issues_df = pd.DataFrame(issues)\n",
    "        display(issues_df)\n",
    "        print(f\"⚠️ {len(issues)} mismatches found!\")\n",
    "    else:\n",
    "        print(\"✅ All homogenized fields match the expected values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede0adcb-e34d-4e81-90e1-8079773eedb6",
   "metadata": {},
   "source": [
    "# Time Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417dc417-cee6-45ba-8306-952ac9bf03f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# ============================================\n",
    "# 1. CONFIGURAÇÃO\n",
    "# ============================================\n",
    "\n",
    "log_dir = \"process001/process_info\"\n",
    "\n",
    "log_files = [\n",
    "    \"prepare_all.log\",\n",
    "    \"import_all.log\",\n",
    "    \"margin_cache_all.log\",\n",
    "    \"crossmatch_and_merge_all.log\",\n",
    "    \"process.log\"\n",
    "]\n",
    "\n",
    "START_RE = re.compile(\n",
    "    r\"(?P<timestamp>\\d{4}-\\d{2}-\\d{2}-\\d{2}:\\d{2}:\\d{2}\\.\\d+): Starting: (?P<task>[\\w_]+) id=(?P<id>[\\w\\d_]+)\"\n",
    ")\n",
    "FINISH_RE = re.compile(\n",
    "    r\"(?P<timestamp>\\d{4}-\\d{2}-\\d{2}-\\d{2}:\\d{2}:\\d{2}\\.\\d+): Finished: (?P<task>[\\w_]+) id=(?P<id>[\\w\\d_]+)\"\n",
    ")\n",
    "\n",
    "# Vamos manter SEMPRE o primeiro start e o último finish de cada task|id\n",
    "start_times = {}\n",
    "end_times = {}\n",
    "\n",
    "# ============================================\n",
    "# 2. LEITURA E PARSE DOS LOGS\n",
    "# ============================================\n",
    "\n",
    "for file in log_files:\n",
    "    path = os.path.join(log_dir, file)\n",
    "    if not os.path.exists(path):\n",
    "        continue\n",
    "\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            m_start = START_RE.search(line)\n",
    "            m_finish = FINISH_RE.search(line)\n",
    "\n",
    "            if m_start:\n",
    "                task_id = f\"{m_start.group('task')}|{m_start.group('id')}\"\n",
    "                ts = datetime.strptime(m_start.group(\"timestamp\"), \"%Y-%m-%d-%H:%M:%S.%f\")\n",
    "                # guarda o menor (primeiro) start\n",
    "                if task_id not in start_times:\n",
    "                    start_times[task_id] = ts\n",
    "                else:\n",
    "                    if ts < start_times[task_id]:\n",
    "                        start_times[task_id] = ts\n",
    "\n",
    "            if m_finish:\n",
    "                task_id = f\"{m_finish.group('task')}|{m_finish.group('id')}\"\n",
    "                ts = datetime.strptime(m_finish.group(\"timestamp\"), \"%Y-%m-%d-%H:%M:%S.%f\")\n",
    "                # guarda o maior (último) finish\n",
    "                if task_id not in end_times:\n",
    "                    end_times[task_id] = ts\n",
    "                else:\n",
    "                    if ts > end_times[task_id]:\n",
    "                        end_times[task_id] = ts\n",
    "\n",
    "# ============================================\n",
    "# 3. CONSTRUÇÃO DO EIXO Y EM ORDEM CUSTOMIZADA\n",
    "# ============================================\n",
    "\n",
    "# Considere apenas tasks que têm start e end\n",
    "all_ids = sorted(set(start_times) & set(end_times))\n",
    "\n",
    "pipeline_init_id = \"pipeline_init|pipeline_init\"\n",
    "consolidate_id = \"consolidate|consolidate\"\n",
    "\n",
    "# IDs de prepare_catalog individuais (exclui o agregador prepare_catalogs)\n",
    "prepare_ids = [\n",
    "    tid for tid in all_ids\n",
    "    if tid.startswith(\"prepare_catalog|\") and tid != \"prepare_catalogs|prepare_catalogs\"\n",
    "]\n",
    "\n",
    "# Ordene os prepares pelo start: quem começa antes aparece antes -> y menor -> \"mais abaixo\" visualmente\n",
    "prepare_ids_sorted = sorted(prepare_ids, key=lambda tid: start_times[tid])\n",
    "\n",
    "# Import cat0 inicial, se existir\n",
    "import_cat0 = [tid for tid in all_ids if tid == \"import_catalog|cat0_hats\"]\n",
    "\n",
    "# Demais tasks (exceto pipeline_init, consolidate, prepares e import_cat0)\n",
    "remaining_ids = [\n",
    "    tid for tid in all_ids\n",
    "    if tid not in prepare_ids + import_cat0 + [pipeline_init_id, consolidate_id]\n",
    "]\n",
    "\n",
    "# Agrupar por step numérico (catX, merged_stepX, etc.) para ordenar dentro dos steps\n",
    "step_dict = defaultdict(list)\n",
    "for tid in remaining_ids:\n",
    "    match = re.search(r\"(?:cat|merged_step)(\\d+)\", tid)\n",
    "    if match:\n",
    "        step = int(match.group(1))\n",
    "        step_dict[step].append(tid)\n",
    "\n",
    "ordered_step_ids = []\n",
    "for step in sorted(step_dict):\n",
    "    step_tasks = step_dict[step]\n",
    "\n",
    "    def task_order(tid):\n",
    "        if tid.startswith(\"import_catalog|cat\"):\n",
    "            return 0\n",
    "        elif tid.startswith(\"generate_margin_cache\"):\n",
    "            return 1\n",
    "        elif tid.startswith(\"crossmatch_and_merge\"):\n",
    "            return 2\n",
    "        elif tid.startswith(\"import_catalog|merged_step\"):\n",
    "            return 3\n",
    "        else:\n",
    "            return 99\n",
    "\n",
    "    # Dentro do step, mantém uma ordem lógica pelas \"fases\"\n",
    "    ordered_step_ids.extend(sorted(step_tasks, key=task_order))\n",
    "\n",
    "# Monta a ordem final: pipeline_init -> prepares (ordenados pelo start) -> import_cat0 -> steps -> consolidate\n",
    "ordered_ids = []\n",
    "if pipeline_init_id in all_ids:\n",
    "    ordered_ids.append(pipeline_init_id)\n",
    "ordered_ids.extend(prepare_ids_sorted)\n",
    "ordered_ids.extend(import_cat0)\n",
    "ordered_ids.extend(ordered_step_ids)\n",
    "if consolidate_id in all_ids:\n",
    "    ordered_ids.append(consolidate_id)\n",
    "\n",
    "# ============================================\n",
    "# 4. MONTAGEM DOS DADOS PARA O PLOT\n",
    "# ============================================\n",
    "\n",
    "# Tempo adicional a ser subtraído do início do pipeline_init (em segundos)\n",
    "aditional_pipeline_init_time = 3  # ⏱️ ajuste aqui conforme necessário\n",
    "\n",
    "# Se existir pipeline_init, ajusta o início para \"andar\" um pouco antes (apenas para estética)\n",
    "if pipeline_init_id in start_times:\n",
    "    start_times[pipeline_init_id] -= timedelta(seconds=aditional_pipeline_init_time)\n",
    "\n",
    "# Zera o tempo no primeiro start dentre os que vamos plotar\n",
    "start_zero = min(start_times[tid] for tid in ordered_ids)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 🛠️ INSERIR REGISTRO MANUAL DA TAREFA \"register\"\n",
    "# --------------------------------------------------\n",
    "register_id = \"register|register\"\n",
    "register_duration = 3  # ⏱️ duração da tarefa \"register\" em segundos\n",
    "\n",
    "# Insere o \"register\" ao final\n",
    "ordered_ids.append(register_id)\n",
    "# Começa após o consolidate (se existir) ou após o último término conhecido\n",
    "if consolidate_id in end_times:\n",
    "    register_start = max(end_times[consolidate_id], *end_times.values())\n",
    "else:\n",
    "    register_start = max(end_times.values())\n",
    "register_end = register_start + timedelta(seconds=register_duration)\n",
    "\n",
    "start_times[register_id] = register_start\n",
    "end_times[register_id] = register_end\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Constrói listas relativas ao start_zero\n",
    "y_labels = []\n",
    "start_list = []\n",
    "end_list = []\n",
    "\n",
    "for tid in ordered_ids:\n",
    "    y_labels.append(tid)\n",
    "    start_rel = (start_times[tid] - start_zero).total_seconds()\n",
    "    end_rel = (end_times[tid] - start_zero).total_seconds()\n",
    "    start_list.append(start_rel)\n",
    "    end_list.append(end_rel)\n",
    "\n",
    "# ============================================\n",
    "# 4b. AJUSTAR POSIÇÕES Y PARA SEPARAR \"register\"\n",
    "# ============================================\n",
    "\n",
    "# Cria posições Y padrão e separa o último (register) com um espaçamento extra\n",
    "y_positions = list(range(len(ordered_ids)))\n",
    "y_positions[-1] += 5.0  # 🛠️ Aumenta a posição do \"register\" no eixo Y\n",
    "\n",
    "# ============================================\n",
    "# 5. PLOTAGEM DO GRÁFICO DE TIME PROFILE\n",
    "# ============================================\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# === Mapear cores por grupo\n",
    "group_colors = {\n",
    "    \"pipeline_init\": \"#003f5c\",       # azul escuro\n",
    "    \"prepare_catalogs\": \"#b8860b\",    # amarelo escuro\n",
    "    \"crossmatch\": \"#2f855a\",          # verde escuro\n",
    "    \"consolidate\": \"#003f5c\",         # mesmo do pipeline_init\n",
    "    \"register\": \"#003f5c\",            # mesmo azul escuro do pipeline_init\n",
    "}\n",
    "\n",
    "# === Determinar grupo de cada tarefa\n",
    "def get_group(tid):\n",
    "    if tid == pipeline_init_id:\n",
    "        return \"pipeline_init\"\n",
    "    elif tid == register_id:\n",
    "        return \"register\"\n",
    "    elif tid in prepare_ids:\n",
    "        return \"prepare_catalogs\"\n",
    "    elif tid == consolidate_id:\n",
    "        return \"consolidate\"\n",
    "    else:\n",
    "        return \"crossmatch\"\n",
    "\n",
    "# === Plotar tarefas com cor unificada para linha e bolinhas\n",
    "for y, start, end, tid in zip(y_positions, start_list, end_list, ordered_ids):\n",
    "    group = get_group(tid)\n",
    "    color = group_colors[group]\n",
    "    plt.hlines(y, start, end, colors=color, linewidth=2)\n",
    "    plt.scatter(start, y, color=color, s=10)  # início\n",
    "    plt.scatter(end, y, color=color, s=10)    # fim\n",
    "\n",
    "# ============================================\n",
    "# Agrupar labels do eixo Y por grupo\n",
    "# ============================================\n",
    "\n",
    "group_positions = defaultdict(list)\n",
    "for y, tid in zip(y_positions, ordered_ids):\n",
    "    group_positions[get_group(tid)].append(y)\n",
    "\n",
    "group_labels = []\n",
    "group_ticks = []\n",
    "\n",
    "for label in [\"pipeline_init\", \"prepare_catalogs\", \"crossmatch\", \"consolidate\", \"register\"]:\n",
    "    if group_positions[label]:\n",
    "        center = sum(group_positions[label]) / len(group_positions[label])\n",
    "        group_labels.append(label)\n",
    "        group_ticks.append(center)\n",
    "\n",
    "# ============================================\n",
    "# Personalização final do gráfico\n",
    "# ============================================\n",
    "\n",
    "plt.yticks(group_ticks, group_labels, fontsize=20)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.xlabel(\"Time (s)\", fontsize=20)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_preparation",
   "language": "python",
   "name": "data_preparation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
